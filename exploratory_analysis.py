#correta 16/06

import tempfile, zipfile, os
from contextlib import redirect_stdout  # Para captura de sa√≠da de info()

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from scipy import stats
from scipy.stats import spearmanr, pearsonr

from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.contingency_tables import Table
from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Para post-hoc Tukey

from pingouin import welch_anova, pairwise_gameshowell  # Para Games-Howell e Welch
import pingouin as pg # Importado aqui para uso direto no show_correlation_matrix_interface

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA  # Para PCA
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from scipy.stats import skew, kurtosis



# --- Fun√ß√µes Auxiliares para c√°lculo de tamanho de efeito ---
# Estas fun√ß√µes s√£o leves, n√£o precisam de cache
def cohens_d(x, y):
    """Calcula o Cohen's d para duas amostras."""
    nx = len(x)
    ny = len(y)
    dof = nx + ny - 2
    pool_std = np.sqrt(((nx - 1) * np.std(x, ddof=1)**2 + (ny - 1) * np.std(y, ddof=1)**2) / dof)
    return (np.mean(x) - np.mean(y)) / pool_std

def cohens_d_paired(x_pre, x_post):
    """Calcula o Cohen's d para amostras pareadas."""
    diff = x_post - x_pre
    return np.mean(diff) / np.std(diff, ddof=1)

def cohens_d_one_sample(data, pop_mean):
    """Calcula o Cohen's d para uma amostra."""
    return (np.mean(data) - pop_mean) / np.std(data, ddof=1)

def calculate_partial_eta_squared(anova_table, effect_term):
    """
    Calcula o Eta-Quadrado Parcial (Œ∑p¬≤) para um termo de efeito na tabela ANOVA.
    Assume que 'anova_table' √© o DataFrame retornado por anova_lm.
    """
    ss_effect = anova_table.loc[effect_term, 'sum_sq']
    ss_error = anova_table.loc['Residual', 'sum_sq']
    
    # anova_lm com typ=2 ou typ=3 para SS_effect, e 'Residual' para SS_error
    if ss_effect + ss_error == 0: # Evitar divis√£o por zero se ambos s√£o 0
        return 0.0
    return ss_effect / (ss_effect + ss_error)


# --- Fun√ß√µes de An√°lise Explorat√≥ria (Refatoradas para Expander e com Cache) ---

# 1. An√°lise de Conting√™ncia
# Aplicar cache_data pois envolve c√°lculo de tabelas e qui-quadrado em potencialmente grandes DataFrames
@st.cache_data(show_spinner=False) # show_spinner=False para controlar o spinner manualmente
def _perform_contingency_analysis_core(df_temp, col1, col2):
    """Fun√ß√£o core para c√°lculo da tabela de conting√™ncia e qui-quadrado."""
    observed_table = pd.crosstab(df_temp[col1].fillna("Valor_Ausente"), df_temp[col2].fillna("Valor_Ausente"), dropna=False)
    
    chi2, p, dof, expected = stats.chi2_contingency(observed_table)
    
    expected_df = pd.DataFrame(expected, index=observed_table.index, columns=observed_table.columns)
    
    table_sm = Table(observed_table)
    standardized_residuals = table_sm.standardized_resids

    data_to_combine = {
        'Observado': observed_table,
        'Esperado': expected_df,
        'Res. Padronizado': standardized_residuals
    }
    combined_table = pd.concat(data_to_combine, axis=1, keys=['Observado', 'Esperado', 'Res. Padronizado'])
    combined_table = combined_table.reorder_levels([1, 0], axis=1).sort_index(axis=1)

    # Diagn√≥stico autom√°tico de domin√¢ncia
    row_prop = pd.crosstab(df_temp[col1], df_temp[col2], normalize='index') * 100
    max_row_share = row_prop.max(axis=1).max()

    return combined_table, chi2, p, dof, max_row_share


def show_contingency_analysis(df):
    st.subheader("An√°lise de Conting√™ncia (Tabelas e Gr√°ficos)")
    st.info("Utilize esta se√ß√£o para explorar a rela√ß√£o entre duas vari√°veis categ√≥ricas ou a distribui√ß√£o de uma √∫nica vari√°vel categ√≥rica.")

    df_temp = df.copy() # C√≥pia para manipula√ß√£o de NaN
    
    cat_cols = df_temp.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()

    if not cat_cols:
        st.warning("N√£o h√° colunas categ√≥ricas ou booleanas no DataFrame para realizar an√°lise de conting√™ncia.")
        return

    analysis_type = st.radio(
        "Selecione o tipo de an√°lise de conting√™ncia:",
        ["Tabela de Frequ√™ncia (1 Vari√°vel)", "Tabela de Conting√™ncia (2 Vari√°veis)"],
        key="contingency_analysis_type"
    )

    if analysis_type == "Tabela de Frequ√™ncia (1 Vari√°vel)":
        col_freqs = st.multiselect(
            "Selecione uma ou mais vari√°veis categ√≥ricas:",
            cat_cols,
            key="contingency_col_freq_multi"
        )
        if st.button("Gerar Tabelas de Frequ√™ncia", key="generate_freq_tables_multi"):
            if not col_freqs:
                st.warning("Selecione pelo menos uma vari√°vel para gerar a(s) tabela(s) de frequ√™ncia.")
            for col_freq in col_freqs:
                st.write(f"### Tabela de Frequ√™ncia para '{col_freq}'")
                # A fun√ß√£o value_counts √© relativamente r√°pida, n√£o h√° necessidade de cache aqui,
                # a menos que o DataFrame seja gigantesco e a chamada seja feita repetidamente
                freq_table = df_temp[col_freq].fillna("Valor_Ausente").value_counts(dropna=False).reset_index()
                freq_table.columns = [col_freq, 'Frequ√™ncia']
                freq_table['Porcentagem (%)'] = (freq_table['Frequ√™ncia'] / freq_table['Frequ√™ncia'].sum()) * 100
                st.dataframe(freq_table)

                fig, ax = plt.subplots(figsize=(10, 6))
                sns.countplot(
                    data=df_temp,
                    y=col_freq,
                    order=df_temp[col_freq].fillna("Valor_Ausente").value_counts(dropna=False).index,
                    ax=ax
                )
                ax.set_title(f'Distribui√ß√£o de {col_freq}')
                ax.set_xlabel('Frequ√™ncia')
                ax.set_ylabel(col_freq)
                st.pyplot(fig)
                plt.close(fig)

    elif analysis_type == "Tabela de Conting√™ncia (2 Vari√°veis)":
        col1 = st.selectbox("Selecione a primeira vari√°vel categ√≥rica:", [""] + cat_cols, index=0, key="contingency_col1")
        col2 = st.selectbox("Selecione a segunda vari√°vel categ√≥rica:", [""] + cat_cols, index=0, key="contingency_col2")

        if st.button("Gerar Tabela de Conting√™ncia e Teste Qui-Quadrado", key="generate_contingency_table"):
            if col1 and col2:
                with st.spinner("Calculando tabela de conting√™ncia e Qui-Quadrado..."):
                    try:
                        combined_table, chi2, p, dof, max_row_share = _perform_contingency_analysis_core(df_temp, col1, col2)
                        
                        st.write(f"### An√°lise de Conting√™ncia Completa para '{col1}' vs '{col2}'")
                        st.dataframe(combined_table.round(3))

                        if max_row_share >= 90:
                            st.warning("üìå Algumas categorias t√™m distribui√ß√£o altamente concentrada (domin√¢ncia > 90%). Pode haver associa√ß√£o forte entre as vari√°veis.")
                        elif max_row_share < 50:
                            st.info("üìå As distribui√ß√µes est√£o relativamente equilibradas entre as categorias.")
                        else:
                            st.info("üìå H√° moderada assimetria na distribui√ß√£o conjunta das vari√°veis.")

                        st.info("Para cada c√©lula, s√£o exibidos: **Observado** (frequ√™ncia real), **Esperado** (frequ√™ncia sob independ√™ncia) e **Res. Padronizado** (desvio da frequ√™ncia esperada, valores |>2| indicam contribui√ß√£o significativa).")

                        st.write("---") # Separador visual

                        st.write("### Resultados do Teste Qui-Quadrado")
                        st.write(f"Estat√≠stica Qui-Quadrado: {chi2:.3f}")
                        st.write(f"Valor p: {p:.3f}")
                        st.write(f"Graus de Liberdade: {dof}")
                        st.write(f"Signific√¢ncia (p < 0.05): {'Sim' if p < 0.05 else 'N√£o'}")

                        if p < 0.05:
                            st.success("H√° evid√™ncias de uma associa√ß√£o significativa entre as duas vari√°veis categ√≥ricas.")
                        else:
                            st.info("N√£o h√° evid√™ncias suficientes para rejeitar a hip√≥tese de independ√™ncia entre as vari√°veis.")

                    except ValueError as e:
                        st.error(f"N√£o foi poss√≠vel realizar o teste Qui-Quadrado. Erro: {e}. Isso pode ocorrer se houver c√©lulas com frequ√™ncia esperada muito baixa (menor que 5) ou se as colunas selecionadas s√£o id√™nticas ap√≥s o preenchimento de NaN.")
                    except Exception as e:
                        st.error(f"Ocorreu um erro inesperado no teste Qui-Quadrado ou no c√°lculo dos res√≠duos: {e}")

                st.write("---") # Separador visual para os gr√°ficos

                st.write("### Gr√°fico de Barras Agrupado")
                fig, ax = plt.subplots(figsize=(12, 7))
                sns.countplot(data=df_temp, x=col1, hue=col2, ax=ax, palette='viridis')
                ax.set_title(f'Contagem de {col1} por {col2}')
                ax.set_xlabel(col1)
                ax.set_ylabel('Contagem')
                plt.xticks(rotation=45, ha='right')
                st.pyplot(fig)
                plt.close(fig)

                st.write("### Gr√°fico de Barras Empilhado (Proporcional)")
                fig, ax = plt.subplots(figsize=(12, 7))
                (df_temp.groupby(col1)[col2].value_counts(normalize=True).unstack(fill_value=0) * 100).plot(kind='bar', stacked=True, ax=ax, cmap='viridis')
                ax.set_title(f'Propor√ß√£o de {col2} dentro de {col1}')
                ax.set_xlabel(col1)
                ax.set_ylabel('Porcentagem (%)')
                plt.xticks(rotation=45, ha='right')
                ax.legend(title=col2, bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(fig)
                plt.close(fig)

            else:
                st.warning("Selecione ambas as vari√°veis para gerar a tabela de conting√™ncia.")

# 2. An√°lise de Correla√ß√£o
@st.cache_data(show_spinner=False)
def _calculate_correlations(df_selected_cols, method):
    """Calcula a matriz de correla√ß√£o para um m√©todo espec√≠fico."""
    return df_selected_cols.corr(method=method)

@st.cache_data(show_spinner=False)
def _calculate_partial_correlation(df_clean, col_x, col_y, col_z):
    """Calcula a correla√ß√£o parcial usando pingouin."""
    return pg.partial_corr(data=df_clean, x=col_x, y=col_y, covar=col_z)

@st.cache_data(show_spinner=False)
def _generate_pairplot(df_selected_pair_cols):
    """Gera o pairplot."""
    return sns.pairplot(df_selected_pair_cols, kind="reg", plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.5}})


def show_correlation_matrix_interface(df):
    st.markdown("### An√°lise de Correla√ß√£o Completa")
    st.info("Abaixo est√£o integradas as an√°lises de Pearson, Spearman, Parcial e por Subgrupos.")

    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    if len(num_cols) < 2:
        st.warning("√â necess√°rio pelo menos duas vari√°veis num√©ricas.")
        return

    st.markdown("#### Correla√ß√£o Pearson + Spearman (por pares)")
    selected_corr_cols = st.multiselect(
        "Selecione vari√°veis num√©ricas:",
        options=num_cols,
        default=[],
        key="corr_combined_vars"
    )
    if selected_corr_cols and len(selected_corr_cols) >= 2:
        with st.spinner("Calculando correla√ß√µes Pearson e Spearman..."):
            pearson_corr = _calculate_correlations(df[selected_corr_cols], "pearson")
            spearman_corr = _calculate_correlations(df[selected_corr_cols], "spearman")

        # --- Tabela de pares ---
        pearson_pairs = pearson_corr.where(np.triu(np.ones(pearson_corr.shape), k=1).astype(bool)).stack().reset_index()
        spearman_pairs = spearman_corr.where(np.triu(np.ones(spearman_corr.shape), k=1).astype(bool)).stack().reset_index()

        pearson_pairs.columns = ["Var1", "Var2", "Pearson"]
        spearman_pairs.columns = ["Var1", "Var2", "Spearman"]

        paired_corrs = pd.merge(pearson_pairs, spearman_pairs, on=["Var1", "Var2"])
        st.dataframe(paired_corrs.round(2))

        # --- Heatmap aprimorado (Pearson) ---
        st.markdown("#### Heatmap de Correla√ß√£o de Pearson")
        fig, ax = plt.subplots(figsize=(min(1.2 * len(selected_corr_cols), 12), 1.2 * len(selected_corr_cols)))
        sns.heatmap(
            pearson_corr,
            annot=True,
            fmt=".2f",
            cmap="RdBu_r",
            center=0,
            square=True,
            linewidths=0.5,
            cbar_kws={"shrink": 0.7},
            ax=ax
        )
        ax.set_title("Matriz de Correla√ß√£o de Pearson", fontsize=14, pad=12)
        st.pyplot(fig)
        plt.close(fig)

    else:
        st.info("Selecione ao menos duas vari√°veis para calcular correla√ß√µes.")


    st.divider()

    st.markdown("#### Correla√ß√£o Total vs Parcial")
    col_x = st.selectbox("Vari√°vel X", [""] + num_cols, index=0, key="partial_x")
    col_y = st.selectbox("Vari√°vel Y", [""] + num_cols, index=0, key="partial_y")
    col_z = st.selectbox("Controlar por (Z)", [""] + num_cols, index=0, key="partial_z")

    if st.button("Calcular Correla√ß√£o Total e Parcial", key="calc_partial_corr"):
        if col_x and col_y and col_z and len(set([col_x, col_y, col_z])) == 3:
            df_clean = df[[col_x, col_y, col_z]].dropna()

            if df_clean.shape[0] < 3:
                st.warning("N√∫mero insuficiente de observa√ß√µes v√°lidas ap√≥s remo√ß√£o de valores ausentes.")
            else:
                with st.spinner("Calculando correla√ß√£o total e parcial..."):
                    r_total, p_total = pearsonr(df_clean[col_x], df_clean[col_y])
                    partial_result = _calculate_partial_correlation(df_clean, col_x, col_y, col_z)

                result_table = pd.DataFrame({
                    "Correla√ß√£o Total (r)": [round(r_total, 3)],
                    "p-valor Total": [round(p_total, 4)],
                    "Correla√ß√£o Parcial (r)": [round(partial_result["r"].iloc[0], 3)],
                    "p-valor Parcial": [round(partial_result["p-val"].iloc[0], 4)]
                })
                st.dataframe(result_table)
        else:
            st.info("Selecione tr√™s vari√°veis distintas para comparar correla√ß√£o total e parcial.")


    st.divider()

    st.markdown("#### Correla√ß√£o por Subgrupo Categ√≥rico")
    group_col = st.selectbox("Vari√°vel categ√≥rica para segmentar:", [""] + cat_cols, index=0, key="group_var")
    group_corr_cols = st.multiselect(
        "Vari√°veis num√©ricas para correla√ß√£o por grupo:",
        options=num_cols,
        default=[],
        key="group_corr_vars"
    )
    if st.button("Calcular Correla√ß√£o por Subgrupo", key="calc_grouped_corr"):
        if group_col and len(group_corr_cols) >= 2:
            with st.spinner(f"Calculando correla√ß√µes por subgrupo para '{group_col}'..."):
                grouped_corrs = []
                for name, group in df.groupby(group_col):
                    try:
                        # Cached call for group correlation
                        corr = _calculate_correlations(group[group_corr_cols], "pearson") 
                        corr = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
                        corr = corr.stack().reset_index()
                        corr.columns = ["Var1", "Var2", f"r_{name}"]
                        grouped_corrs.append(corr)
                    except Exception as e:
                        st.warning(f"Erro no grupo '{name}': {e}")
                if grouped_corrs:
                    merged = grouped_corrs[0]
                    for other in grouped_corrs[1:]:
                        merged = pd.merge(merged, other, on=["Var1", "Var2"], how="outer")
                    st.dataframe(merged.round(2))
                else:
                    st.warning("N√£o foi poss√≠vel calcular correla√ß√µes para os grupos selecionados.")
        elif group_col:
            st.info("Selecione ao menos duas vari√°veis num√©ricas.")
        elif group_corr_cols:
            st.info("Selecione a vari√°vel categ√≥rica para segmenta√ß√£o.")
        else:
            st.info("Selecione a vari√°vel categ√≥rica e ao menos duas vari√°veis num√©ricas.")


    st.divider()

    st.markdown("#### Gr√°fico de Dispers√£o entre Pares")
    selected_pair_cols = st.multiselect(
        "Selecione vari√°veis para gr√°fico de pares:",
        options=num_cols,
        default=[],
        key="pairplot_vars"
    )
    if st.button("Gerar Gr√°fico de Pares", key="generate_pairplot_button"):
        if len(selected_pair_cols) >= 2:
            st.markdown("#### Gr√°fico de Dispers√£o com Regress√£o Linear (Pairplot)")
            with st.spinner("Gerando Pairplot (pode demorar para muitos dados/colunas)..."):
                fig = _generate_pairplot(df[selected_pair_cols])
                st.pyplot(fig)
                plt.close(fig.fig) # CHANGED THIS LINE: access the .fig attribute
        elif selected_pair_cols:
            st.warning("Selecione ao menos duas vari√°veis.")
        else:
            st.info("Selecione as vari√°veis para gerar o gr√°fico de pares.")


# 3. An√°lise ANOVA
@st.cache_data(show_spinner=False)
def _perform_anova_core(df_anova, dv_col, iv_cols):
    """Fun√ß√£o core para execu√ß√£o da ANOVA."""
    formula_terms = [f'C({col})' for col in iv_cols]
    if len(formula_terms) > 1:
        formula = f"{dv_col} ~ {' * '.join(formula_terms)}"
    else:
        formula = f"{dv_col} ~ {formula_terms[0]}"
    
    model = ols(formula, data=df_anova).fit()
    anova_table = anova_lm(model, typ=2)
    return anova_table, formula

@st.cache_data(show_spinner=False)
def _perform_levene_test(df_anova, dv_col, iv_cols):
    """Fun√ß√£o core para execu√ß√£o do Teste de Levene."""
    if len(iv_cols) > 1:
        df_anova['_combined_group_'] = df_anova[iv_cols].astype(str).agg('_'.join, axis=1)
        levene_groups = [df_anova[dv_col][df_anova['_combined_group_'] == g].dropna() for g in df_anova['_combined_group_'].unique()]
    else:
        levene_groups = [df_anova[dv_col][df_anova[iv_cols[0]] == g].dropna() for g in df_anova[iv_cols[0]].unique()]

    levene_groups = [g for g in levene_groups if not g.empty]

    if len(levene_groups) < 2:
        return None, 1.0 # N√£o foi poss√≠vel rodar Levene, retorna p-val 1.0 (homog√™neo)
    
    stat_levene, levene_p_val = stats.levene(*levene_groups)
    return stat_levene, levene_p_val

@st.cache_data(show_spinner=False)
def _perform_tukey_hsd(endog_data, groups_data):
    """Executa o teste post-hoc Tukey HSD."""
    return pairwise_tukeyhsd(endog=endog_data, groups=groups_data, alpha=0.05)

@st.cache_data(show_spinner=False)
def _perform_games_howell(df, dv_col, between_col):
    """Executa o teste post-hoc Games-Howell."""
    # This line is correct, it passes dv_col to pingouin's dv, etc.
    return pg.pairwise_gameshowell(data=df, dv=dv_col, between=between_col)
    with st.spinner("Executando Games-Howell..."):
        try:
            gameshowell_result = _perform_games_howell(
                df=df_anova_results,
                dv_col=dv_col_results, # <--- ENSURE THIS IS 'dv_col'
                between_col=selected_posthoc_factor # <--- ENSURE THIS IS 'between_col'
            )
            gameshowell_result["Significativo?"] = gameshowell_result["pval"].apply(lambda p: "‚úÖ Sim" if p < 0.05 else "‚ùå N√£o")
            for col in ["diff", "se", "pval", "ci_low", "ci_high"]:
                if col in gameshowell_result.columns:
                    gameshowell_result[col] = gameshowell_result[col].round(3)
            st.markdown("#### Resultados do Games-Howell (com destaque para signific√¢ncia)")
            st.dataframe(gameshowell_result)
        except Exception as e:
            st.error(f"Erro ao executar Games-Howell: {e}")

def show_anova_analysis(df):
    st.subheader("An√°lise de Vari√¢ncia (ANOVA)")
    st.info("Utilize a ANOVA para verificar se h√° diferen√ßas significativas entre as m√©dias de grupos.")

    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()

    if not num_cols:
        st.warning("N√£o h√° colunas num√©ricas (vari√°vel dependente) no DataFrame para realizar a ANOVA.")
        return
    if not cat_cols:
        st.warning("N√£o h√° colunas categ√≥ricas (vari√°veis independentes) no DataFrame para realizar a ANOVA.")
        return

    # 1. Sele√ß√£o da Vari√°vel Dependente
    dv_col = st.selectbox("Vari√°vel Dependente (Num√©rica):", [""] + num_cols, index=0, key="anova_dv_col")
    if dv_col == "":
        st.info("Selecione a vari√°vel dependente para continuar.")
        return

    # 2. Sele√ß√£o do Tipo de ANOVA (Unifatorial ou Fatorial)
    anova_type = st.radio(
        "Tipo de ANOVA:",
        ["ANOVA Unifatorial (um fator)", "ANOVA Fatorial (dois ou mais fatores)"],
        key="anova_selection_type"
    )

    iv_cols = []
    if anova_type == "ANOVA Unifatorial (um fator)":
        iv_col = st.selectbox("Vari√°vel Independente (Categ√≥rica - Fator):", [""] + cat_cols, index=0, key="anova_iv_col_unifactorial")
        if iv_col == "":
            st.info("Selecione a vari√°vel independente para continuar.")
            return
        iv_cols.append(iv_col)
    else:  # ANOVA Fatorial
        iv_cols = st.multiselect("Vari√°veis Independentes (Categ√≥ricas - Fatores):", cat_cols, default=[], key="anova_iv_cols_factorial")
        if not iv_cols or len(iv_cols) < 2:
            st.warning("Para ANOVA Fatorial, selecione pelo menos duas vari√°veis independentes.")
            return

    if st.button("Executar An√°lise ANOVA", key="run_anova"):
        # Limpa resultados anteriores para evitar confus√£o se o usu√°rio mudar as sele√ß√µes
        for key in ['anova_results', 'anova_table', 'levene_p_anova', 'anova_dv_current', 'anova_ivs_current']:
            if key in st.session_state:
                del st.session_state[key]

        st.session_state['anova_dv_current'] = dv_col
        st.session_state['anova_ivs_current'] = iv_cols

        st.write(f"### ANOVA para '{st.session_state['anova_dv_current']}' por {st.session_state['anova_ivs_current']}")

        cols_for_anova = [st.session_state['anova_dv_current']] + st.session_state['anova_ivs_current']
        df_anova = df[cols_for_anova].dropna()

        if df_anova.empty:
            st.warning("N√£o h√° dados suficientes ap√≥s remover valores faltantes para realizar a ANOVA com as colunas selecionadas.")
            return

        for iv in st.session_state['anova_ivs_current']:
            unique_groups = df_anova[iv].unique()
            if len(unique_groups) < 2:
                st.warning(f"A vari√°vel independente '{iv}' deve ter pelo menos dois grupos distintos.")
                return
            if anova_type == "ANOVA Unifatorial (um fator)" and len(unique_groups) < 3:
                st.info(f"A vari√°vel independente '{iv}' tem apenas {len(unique_groups)} grupos. A ANOVA √© mais apropriada para tr√™s ou mais grupos. Para dois grupos, considere um teste t.")

        st.write("#### Teste de Homogeneidade de Vari√¢ncias (Levene's Test)")
        with st.spinner("Executando Teste de Levene..."):
            stat_levene, levene_p_val = _perform_levene_test(df_anova, st.session_state['anova_dv_current'], st.session_state['anova_ivs_current'])
        
        if stat_levene is None: # Se _perform_levene_test retornou None, significa que n√£o havia dados suficientes
            st.warning("N√£o h√° grupos suficientes com dados v√°lidos para realizar o Teste de Levene.")
            st.info("Prosseguindo com a ANOVA sem avalia√ß√£o detalhada de homogeneidade de vari√¢ncias.")
            levene_p_val = 1.0 # Assume homogeneidade para n√£o bloquear
        else:
            st.write(f"Estat√≠stica de Levene: {stat_levene:.3f}")
            st.write(f"Valor p de Levene: {levene_p_val:.3f}")
            if levene_p_val < 0.05:
                st.warning("As vari√¢ncias entre os grupos N√ÉO s√£o homog√™neas (p < 0.05). Considere usar o teste de Welch ANOVA para an√°lises unifatoriais ou esteja ciente para as an√°lises post-hoc.")
            else:
                st.success("As vari√¢ncias entre os grupos s√£o homog√™neas (p >= 0.05).")
        
        st.session_state['levene_p_anova'] = levene_p_val

        st.write("#### Resultados da ANOVA")
        with st.spinner("Executando ANOVA..."):
            try:
                anova_table, formula = _perform_anova_core(df_anova, st.session_state['anova_dv_current'], st.session_state['anova_ivs_current'])

                anova_table_fmt = (
                    anova_table
                    .reset_index()
                    .rename(columns={
                        "index": "Termo",
                        "sum_sq": "Soma dos Quadrados",
                        "df": "GL",
                        "F": "Estat√≠stica F",
                        "PR(>F)": "Valor p"
                    })
                    .round(3)
                )

                st.markdown("#### Tabela ANOVA")
                st.dataframe(anova_table_fmt)

                st.write("#### Tamanho do Efeito (Eta-Quadrado Parcial, Œ∑p¬≤)")
                eta_squared_data = []
                for term in anova_table.index:
                    if term not in ['Residual', 'Intercept']:
                        eta_p2 = calculate_partial_eta_squared(anova_table, term)
                        eta_squared_data.append({'Termo': term, 'Œ∑p¬≤': eta_p2})
                
                if eta_squared_data:
                    eta_squared_df = pd.DataFrame(eta_squared_data)
                    st.dataframe(eta_squared_df.set_index('Termo').round(3))
                    st.info("Interpreta√ß√£o do Œ∑p¬≤ (Cohen): 0.01 (pequeno), 0.06 (m√©dio), 0.14 (grande).")
                else:
                    st.info("Nenhum termo de efeito para calcular Œ∑p¬≤.")

                st.session_state['anova_results'] = {
                    'df_anova': df_anova,
                    'dv_col': st.session_state['anova_dv_current'],
                    'iv_cols': st.session_state['anova_ivs_current'],
                    'anova_table': anova_table,
                    'formula': formula
                }
                st.session_state['anova_table'] = anova_table

                p_val_overall_significant = False
                for term in iv_cols:
                    term_name = f"C({term})"
                    if term_name in anova_table.index and anova_table.loc[term_name, 'PR(>F)'] < 0.05:
                        p_val_overall_significant = True
                        break

                if len(iv_cols) > 1:
                    interaction_term = ":".join([f"C({col})" for col in iv_cols])
                    if interaction_term in anova_table.index and anova_table.loc[interaction_term, 'PR(>F)'] < 0.05:
                        p_val_overall_significant = True

                if p_val_overall_significant:
                    st.success("‚úÖ H√° pelo menos um efeito estatisticamente significativo (p < 0.05). Prossiga para a an√°lise Post-Hoc.")
                else:
                    st.info("‚ÑπÔ∏è Nenhum dos termos da ANOVA foi estatisticamente significativo (p ‚â• 0.05). Post-hoc n√£o √© necess√°rio.")

            except Exception as e:
                st.error(f"Erro ao executar ANOVA: {e}. Verifique se as vari√°veis selecionadas s√£o apropriadas e se n√£o h√° problemas nos dados (ex: poucas observa√ß√µes por grupo, vari√¢ncia zero).")
                for key in ['anova_results', 'anova_table', 'levene_p_anova']:
                    if key in st.session_state:
                        del st.session_state[key]
            
    if 'anova_results' in st.session_state and 'anova_table' in st.session_state:
        st.write("---")
        st.write("#### An√°lise Post-Hoc (Compara√ß√µes M√∫ltiplas)")
        st.info("Esta se√ß√£o permite realizar compara√ß√µes post-hoc se a ANOVA geral indicar um efeito significativo.")

        df_anova_results = st.session_state['anova_results']['df_anova']
        dv_col_results = st.session_state['anova_results']['dv_col']
        iv_cols_results = st.session_state['anova_results']['iv_cols']
        anova_table_results = st.session_state['anova_table']
        levene_p_val_results = st.session_state['levene_p_anova']

        significant_main_factors = []
        for factor in iv_cols_results:
            term_name = f'C({factor})'
            if term_name in anova_table_results.index and anova_table_results.loc[term_name, 'PR(>F)'] < 0.05:
                significant_main_factors.append(factor)
        
        significant_interaction_terms = []
        if len(iv_cols_results) > 1:
            interaction_term_name = ':'.join([f'C({c})' for c in iv_cols_results])
            if interaction_term_name in anova_table_results.index and anova_table_results.loc[interaction_term_name, 'PR(>F)'] < 0.05:
                significant_interaction_terms.append("Intera√ß√£o: " + " x ".join(iv_cols_results))

        if not significant_main_factors and not significant_interaction_terms:
            st.info("N√£o h√° fatores principais ou termos de intera√ß√£o significativos na ANOVA geral para realizar an√°lises post-hoc.")
        else:
            st.markdown("**Fatores/Intera√ß√µes Significativas para An√°lise Post-Hoc:**")
            for factor in significant_main_factors:
                st.write(f"- {factor}")
            for term in significant_interaction_terms:
                st.write(f"- {term}")

            if significant_main_factors:
                selected_posthoc_factor = st.selectbox(
                    "Selecione o fator principal para an√°lise Post-Hoc:",
                    significant_main_factors,
                    key="posthoc_factor_select"
                )

                if selected_posthoc_factor:
                    st.write(f"Compara√ß√£o Post-Hoc para: **{selected_posthoc_factor}**")
                    posthoc_method = st.selectbox(
                        "Selecione o m√©todo Post-Hoc:",
                        ["Tukey HSD (se vari√¢ncias homog√™neas)", "Games-Howell (se vari√¢ncias heterog√™neas)"],
                        key=f"posthoc_method_select_{selected_posthoc_factor}"
                    )

                    if st.button(f"Executar Post-Hoc para {selected_posthoc_factor}", key=f"run_posthoc_button_{selected_posthoc_factor}"):
                        if posthoc_method == "Tukey HSD (se vari√¢ncias homog√™neas)":
                            if levene_p_val_results < 0.05:
                                st.warning("Tukey HSD assume homogeneidade das vari√¢ncias. O teste de Levene indicou heterogeneidade. Considere Games-Howell.")
                            with st.spinner("Executando Tukey HSD..."):
                                try:
                                    tukey_result = _perform_tukey_hsd(
                                        endog_data=df_anova_results[dv_col_results],
                                        groups_data=df_anova_results[selected_posthoc_factor]
                                    )
                                    tukey_df = pd.DataFrame(data=tukey_result._results_table.data[1:], columns=tukey_result._results_table.data[0])
                                    tukey_df["Significativo?"] = tukey_df["p-adj"].apply(lambda p: "‚úÖ Sim" if float(p) < 0.05 else "‚ùå N√£o")
                                    tukey_df[["meandiff", "p-adj", "lower", "upper"]] = tukey_df[["meandiff", "p-adj", "lower", "upper"]].astype(float).round(3)
                                    st.markdown("#### Resultados do Tukey HSD (com destaque para signific√¢ncia)")
                                    st.dataframe(tukey_df)
                                    fig = tukey_result.plot_simultaneous()
                                    st.pyplot(fig)
                                    plt.close(fig)
                                except Exception as e:
                                    st.error(f"Erro ao executar Tukey HSD: {e}")
                        elif posthoc_method == "Games-Howell (se vari√¢ncias heterog√™neas)":
                            if levene_p_val_results >= 0.05:
                                st.warning("Games-Howell √© para vari√¢ncias heterog√™neas. O teste de Levene indicou homogeneidade. Considere Tukey HSD.")
                            with st.spinner("Executando Games-Howell..."):
                                try:
                                    gameshowell_result = _perform_games_howell(
                                    df=df_anova_results,
                                    dv_col=dv_col_results,
                                    between_col=selected_posthoc_factor
)
                                    gameshowell_result["Significativo?"] = gameshowell_result["pval"].apply(lambda p: "‚úÖ Sim" if p < 0.05 else "‚ùå N√£o")
                                    for col in ["diff", "se", "pval", "ci_low", "ci_high"]:
                                        if col in gameshowell_result.columns:
                                            gameshowell_result[col] = gameshowell_result[col].round(3)
                                    st.markdown("#### Resultados do teste post hoc Games-Howell ")
                                    st.dataframe(gameshowell_result)
                                except Exception as e:
                                    st.error(f"Erro ao executar Games-Howell: {e}")
            else:
                st.info("Nenhum fator principal significativo para an√°lise post-hoc individual.")

            if significant_interaction_terms:
                st.write("---")
                st.write("#### Interpreta√ß√£o de Intera√ß√£o")
                st.info("Quando um termo de intera√ß√£o √© significativo, a rela√ß√£o de um fator com a vari√°vel dependente muda a depender dos n√≠veis do outro fator. Deve ser interpretada com gr√°ficos de intera√ß√£o.")
                st.warning("A interpreta√ß√£o de intera√ß√µes √© complexa e usualmente exigir visualiza√ß√µes espec√≠ficas.")

    st.write("---")
    st.write("#### Gr√°ficos de Visualiza√ß√£o dos Grupos")
    if 'anova_results' in st.session_state:
        df_anova_plot = st.session_state['anova_results']['df_anova']
        dv_col_plot = st.session_state['anova_results']['dv_col']
        iv_cols_plot = st.session_state['anova_results']['iv_cols']

        for iv_plot in iv_cols_plot:
            st.write(f"##### Gr√°fico de M√©dias de {dv_col_plot} por {iv_plot}")
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(data=df_anova_plot, x=iv_plot, y=dv_col_plot, errorbar='se', ax=ax, palette='viridis')
            ax.set_title(f'M√©dia de {dv_col_plot} por {iv_plot} com Erro Padr√£o')
            ax.set_xlabel(iv_plot)
            ax.set_ylabel(f'M√©dia de {dv_col_plot}')
            st.pyplot(fig)
            plt.close(fig)

            st.write(f"##### Boxplot de {dv_col_plot} por {iv_plot}")
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.boxplot(data=df_anova_plot, x=iv_plot, y=dv_col_plot, ax=ax, palette='viridis')
            sns.stripplot(data=df_anova_plot, x=iv_plot, y=dv_col_plot, color='black', size=3, jitter=True, ax=ax)
            ax.set_title(f'Boxplot de {dv_col_plot} por {iv_plot}')
            ax.set_xlabel(iv_plot)
            ax.set_ylabel(dv_col_plot)
            st.pyplot(fig)
            plt.close(fig)
        
        if len(iv_cols_plot) == 2:
            st.write(f"##### Gr√°fico de Intera√ß√£o para {iv_cols_plot[0]} x {iv_cols_plot[1]}")
            fig, ax = plt.subplots(figsize=(12, 7))
            sns.pointplot(data=df_anova_plot, x=iv_cols_plot[0], y=dv_col_plot, hue=iv_cols_plot[1], 
                          errorbar='se', dodge=True, ax=ax, palette='dark')
            ax.set_title(f'Gr√°fico de Intera√ß√£o de {dv_col_plot} por {iv_cols_plot[0]} e {iv_cols_plot[1]}')
            ax.set_xlabel(iv_cols_plot[0])
            ax.set_ylabel(dv_col_plot)
            ax.legend(title=iv_cols_plot[1], bbox_to_anchor=(1.05, 1), loc='upper left')
            st.pyplot(fig)
            plt.close(fig)
        elif len(iv_cols_plot) > 2:
            st.info("Para mais de dois fatores, a visualiza√ß√£o de intera√ß√£o se torna complexa e n√£o √© gerada automaticamente aqui.")
    else:
        st.info("Execute a an√°lise ANOVA para visualizar os gr√°ficos dos grupos.")




# 4. Testes T
# Os testes T s√£o geralmente r√°pidos, mas para garantir, podemos cachear as fun√ß√µes que chamam stats.ttest
@st.cache_data(show_spinner=False)
def _perform_one_sample_ttest(sample_data, pop_mean):
    """Executa o teste t de uma amostra."""
    stat, p = stats.ttest_1samp(sample_data, pop_mean)
    return stat, p # Return serializable values

@st.cache_data(show_spinner=False)
def _perform_independent_ttest(group1_data, group2_data, equal_var):
    """Executa o teste t independente."""
    stat, p = stats.ttest_ind(group1_data, group2_data, equal_var=equal_var)
    return stat, p # Return serializable values

@st.cache_data(show_spinner=False)
def _perform_levene_independent_ttest(group1_data, group2_data):
    """Executa o teste de Levene para o teste t independente."""
    stat, p = stats.levene(group1_data, group2_data)
    return stat, p # Return serializable values (Levene's also returns a similar object)


@st.cache_data(show_spinner=False)
def _perform_paired_ttest(df_paired_col_pre, df_paired_col_post):
    """Executa o teste t pareado."""
    stat, p = stats.ttest_rel(df_paired_col_pre, df_paired_col_post)
    return stat, p # Return serializable values

# ... (rest of the code) ...

def show_t_tests(df):
    st.subheader("Testes T")
    st.info("Realize testes t para comparar m√©dias de uma ou duas amostras.")

    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()

    if not num_cols:
        st.warning("N√£o h√° colunas num√©ricas no DataFrame para realizar testes t.")
        return

    test_type = st.radio(
        "Selecione o tipo de teste T:",
        ["Teste T de Uma Amostra", "Teste T de Duas Amostras (Independentes)", "Teste T de Amostras Pareadas"],
        key="t_test_type"
    )

    if test_type == "Teste T de Uma Amostra":
        st.markdown("#### Teste T de Uma Amostra")
        one_sample_col = st.selectbox("Selecione a vari√°vel num√©rica:", [""] + num_cols, index=0, key="one_sample_col")
        pop_mean = st.number_input("M√©dia da popula√ß√£o a ser testada (Œº‚ÇÄ):", value=0.0, key="pop_mean")

        if one_sample_col == "":
            st.info("Selecione uma vari√°vel num√©rica.")
        else:
            if st.button("Executar Teste T de Uma Amostra", key="run_one_sample_t_test"):
                sample_data = df[one_sample_col].dropna()
                if sample_data.empty:
                    st.warning("A coluna selecionada n√£o possui dados v√°lidos para o teste de uma amostra.")
                    return
                with st.spinner("Executando Teste T de Uma Amostra..."):
                    stat, p = _perform_one_sample_ttest(sample_data, pop_mean)
                d = cohens_d_one_sample(sample_data, pop_mean)

                st.write(f"### Resultados do Teste T de Uma Amostra para '{one_sample_col}'")
                st.write(f"M√©dia da Amostra: {sample_data.mean():.3f}")
                st.write(f"Desvio Padr√£o da Amostra: {sample_data.std():.3f}")
                st.write(f"Estat√≠stica T: {stat:.3f}")
                st.write(f"Valor p: {p:.3f}")
                st.write(f"Graus de Liberdade: {len(sample_data) - 1}")
                st.write(f"Cohen's d (Tamanho do Efeito): {d:.3f}")

                if p < 0.05:
                    st.success(f"A m√©dia da amostra √© significativamente diferente da m√©dia da popula√ß√£o ({pop_mean}).")
                else:
                    st.info(f"N√£o h√° diferen√ßa significativa entre a m√©dia da amostra e a m√©dia da popula√ß√£o ({pop_mean}).")

    elif test_type == "Teste T de Duas Amostras (Independentes)":
        st.markdown("#### Teste T de Duas Amostras Independentes")
        dv_col_ind = st.selectbox("Vari√°vel Dependente (Num√©rica):", [""] + num_cols, index=0, key="dv_col_ind")
        group_col_ind = st.selectbox("Vari√°vel de Agrupamento (Categ√≥rica, 2 grupos):", [""] + cat_cols, index=0, key="group_col_ind")

        if dv_col_ind == "" or group_col_ind == "":
            st.info("Selecione as duas vari√°veis.")
        else:
            unique_groups = df[group_col_ind].dropna().unique().tolist()
            if len(unique_groups) != 2:
                st.warning("A vari√°vel de agrupamento deve ter exatamente dois valores √∫nicos.")
                if len(unique_groups) > 2:
                    st.info(f"Vari√°vel '{group_col_ind}' tem mais de 2 grupos: {unique_groups}. Considere usar ANOVA.")
                return

            group1_name, group2_name = unique_groups
            st.write(f"Grupos detectados: '{group1_name}' e '{group2_name}'.")

            if st.button("Executar Teste T Independente", key="run_independent_t_test"):
                df_filtered = df[[dv_col_ind, group_col_ind]].dropna()
                group1_data = df_filtered[df_filtered[group_col_ind] == group1_name][dv_col_ind]
                group2_data = df_filtered[df_filtered[group_col_ind] == group2_name][dv_col_ind]

                if group1_data.empty or group2_data.empty:
                    st.warning("Um dos grupos est√° vazio ap√≥s a remo√ß√£o de valores faltantes.")
                    return

                st.write("#### Estat√≠sticas Descritivas por Grupo")
                st.write(f"**Grupo '{group1_name}':** M√©dia={group1_data.mean():.3f}, DP={group1_data.std():.3f}, N={len(group1_data)}")
                st.write(f"**Grupo '{group2_name}':** M√©dia={group2_data.mean():.3f}, DP={group2_data.std():.3f}, N={len(group2_data)}")

                with st.spinner("Executando Teste de Levene..."):
                    stat_levene, p_levene = _perform_levene_independent_ttest(group1_data, group2_data)
                
                equal_var = p_levene >= 0.05
                st.write("#### Teste de Homogeneidade de Vari√¢ncias (Levene)")
                st.write(f"Estat√≠stica: {stat_levene:.3f}, Valor p: {p_levene:.3f}")
                st.success("Vari√¢ncias homog√™neas.") if equal_var else st.warning("Vari√¢ncias n√£o homog√™neas (usando Welch).")

                with st.spinner("Executando Teste T Independente..."):
                    stat_t, p_t = _perform_independent_ttest(group1_data, group2_data, equal_var=equal_var)
                d = cohens_d(group1_data, group2_data)

                st.write("#### Resultado do Teste T")
                st.write(f"Estat√≠stica T: {stat_t:.3f}")
                st.write(f"Valor p: {p_t:.3f}")
                st.write(f"Cohen's d: {d:.3f}")

                if p_t < 0.05:
                    maior = group1_name if group1_data.mean() > group2_data.mean() else group2_name
                    st.success(f"H√° diferen√ßa significativa: o grupo **{maior}** tem m√©dia maior.")
                else:
                    st.info("N√£o foi encontrada diferen√ßa significativa entre os grupos.")

    elif test_type == "Teste T de Amostras Pareadas":
        st.markdown("#### Teste T de Amostras Pareadas")
        paired_cols = [col for col in num_cols if df[col].nunique() > 1]
        col_pre = st.selectbox("Vari√°vel 'Pr√©':", [""] + paired_cols, index=0, key="col_pre_paired")
        col_post = st.selectbox("Vari√°vel 'P√≥s':", [""] + paired_cols, index=0, key="col_post_paired")

        if col_pre == "" or col_post == "":
            st.info("Selecione ambas as vari√°veis.")
        elif col_pre == col_post:
            st.warning("As vari√°veis devem ser diferentes.")
        else:
            if st.button("Executar Teste T Pareado", key="run_paired_t_test"):
                df_paired = df[[col_pre, col_post]].dropna()
                if df_paired.empty:
                    st.warning("N√£o h√° dados suficientes para o teste pareado.")
                    return
                with st.spinner("Executando Teste T Pareado..."):
                    stat, p = _perform_paired_ttest(df_paired[col_pre], df_paired[col_post])
                d = cohens_d_paired(df_paired[col_pre], df_paired[col_post])

                st.write(f"### Resultado do Teste T Pareado: '{col_pre}' vs '{col_post}'")
                st.write(f"Estat√≠stica T: {stat:.3f}")
                st.write(f"Valor p: {p:.3f}")
                st.write(f"Cohen's d: {d:.3f}")

                if p < 0.05:
                    st.success("Diferen√ßa significativa entre as condi√ß√µes.")
                else:
                    st.info("N√£o h√° diferen√ßa estatisticamente significativa.")

# 5. Clustering
@st.cache_data(show_spinner=False)
def _perform_kmeans_and_pca(scaled_data, num_clusters):
    """Executa K-Means e PCA para visualiza√ß√£o."""
    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')
    cluster_labels = kmeans.fit_predict(scaled_data)

    silhouette_avg = None
    if num_clusters > 1:
        silhouette_avg = silhouette_score(scaled_data, cluster_labels)

    pca = None
    principal_components = None
    pca_explained_variance_ratio = None
    if scaled_data.shape[1] >= 2:
        pca = PCA(n_components=2)
        principal_components = pca.fit_transform(scaled_data)
        pca_explained_variance_ratio = pca.explained_variance_ratio_

    return cluster_labels, silhouette_avg, principal_components, pca_explained_variance_ratio


def show_clustering_analysis(df):
    st.subheader("An√°lise de Clusters (K-Means)")
    st.info("Utilize a An√°lise de Clusters para identificar grupos homog√™neos (segmentos) dentro dos seus dados, com base nas caracter√≠sticas selecionadas.")

    if 'df_processed' in st.session_state and not st.session_state.df_processed.empty:
        df_base_for_clustering = st.session_state.df_processed.copy()
        st.info("Utilizando o DataFrame processado da sess√£o para a an√°lise de clusters.")
    else:
        df_base_for_clustering = df.copy()
        st.warning("DataFrame processado n√£o encontrado na sess√£o. Utilizando o DataFrame original carregado para a an√°lise de clusters. Por favor, certifique-se de carregar e pr√©-processar os dados primeiro.")

    num_cols = df_base_for_clustering.select_dtypes(include=np.number).columns.tolist()

    if not num_cols:
        st.error("N√£o h√° colunas num√©ricas no DataFrame base para realizar a an√°lise de clusters ap√≥s o pr√©-processamento. O K-Means requer dados num√©ricos.")
        return

    st.markdown("### Sele√ß√£o de Vari√°veis para Clustering")
    selected_cols_for_clustering = st.multiselect(
        "Selecione as vari√°veis num√©ricas para usar na an√°lise de clusters:",
        num_cols,
        key="cluster_cols_select"
    )

    if not selected_cols_for_clustering:
        st.info("Por favor, selecione pelo menos duas vari√°veis para realizar a an√°lise de clusters.")
        return

    df_cluster_raw = df_base_for_clustering[selected_cols_for_clustering].copy()
    initial_rows = df_cluster_raw.shape[0]
    for col in df_cluster_raw.columns:
        df_cluster_raw[col] = pd.to_numeric(df_cluster_raw[col], errors='coerce')

    df_cluster_clean = df_cluster_raw.dropna()

    if df_cluster_clean.shape[0] < initial_rows:
        st.warning(f"Foram removidas {initial_rows - df_cluster_clean.shape[0]} linhas contendo valores ausentes ou n√£o-num√©ricos nas vari√°veis selecionadas para clustering. Restam {df_cluster_clean.shape[0]} observa√ß√µes v√°lidas.")

    if df_cluster_clean.empty:
        st.error("N√£o h√° dados suficientes para clusterizar ap√≥s a limpeza e remo√ß√£o de valores ausentes/n√£o-num√©ricos nas colunas selecionadas. Por favor, ajuste suas vari√°veis de sele√ß√£o ou verifique a qualidade dos dados.")
        return

    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(df_cluster_clean)
    scaled_df = pd.DataFrame(scaled_data, columns=selected_cols_for_clustering, index=df_cluster_clean.index)

    st.markdown("### 1. Determina√ß√£o do N√∫mero Ideal de Clusters (M√©todo do Cotovelo)")
    max_k_elbow = min(15, len(scaled_df) - 1)
    if max_k_elbow < 2:
        st.warning(f"Dados insuficientes ({len(scaled_df)} observa√ß√µes) para realizar o m√©todo do cotovelo.")
        return

    inertias = []
    k_range_elbow = range(1, max_k_elbow + 1)

    with st.spinner("Calculando in√©rcias para o M√©todo do Cotovelo..."):
        for k in k_range_elbow:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
            kmeans.fit(scaled_data)
            inertias.append(kmeans.inertia_)

    fig_elbow, ax_elbow = plt.subplots(figsize=(10, 6))
    ax_elbow.plot(k_range_elbow, inertias, marker='o')
    ax_elbow.set_title('M√©todo do Cotovelo para K-Means (In√©rcia vs. N√∫mero de Clusters)')
    ax_elbow.set_xlabel('N√∫mero de Clusters (k)')
    ax_elbow.set_ylabel('In√©rcia')
    ax_elbow.set_xticks(k_range_elbow)
    st.pyplot(fig_elbow)
    plt.close(fig_elbow)

    st.markdown("### 2. Execu√ß√£o do K-Means e Avalia√ß√£o")
    num_clusters = st.number_input(
        "Insira o n√∫mero de clusters (k) para o K-Means (m√≠nimo 2):",
        min_value=2,
        max_value=max_k_elbow,
        value=min(3, max_k_elbow),
        key="k_input"
    )

    if st.button("Executar K-Means", key="run_kmeans_button"):
        with st.spinner(f"Executando K-Means com {num_clusters} clusters e PCA para visualiza√ß√£o..."):
            try:
                cluster_labels, silhouette_avg, principal_components, pca_explained_variance_ratio = \
                    _perform_kmeans_and_pca(scaled_data, num_clusters)

                if silhouette_avg is not None:
                    st.success(f"Silhouette Score: {silhouette_avg:.3f}")
                    st.info("O Silhouette Score varia de -1 (pior) a +1 (melhor). Valores pr√≥ximos de 1 indicam clusters bem definidos e separados. Valores pr√≥ximos de 0 indicam sobreposi√ß√£o. Valores negativos indicam atribui√ß√£o incorreta.")

                st.session_state['cluster_labels_latest'] = cluster_labels
                st.session_state['cluster_features_latest'] = selected_cols_for_clustering
                st.session_state['scaled_data_for_pca'] = scaled_data

            except Exception as e:
                st.error(f"Ocorreu um erro ao executar o K-Means: {e}. Verifique a sele√ß√£o das vari√°veis e o n√∫mero de clusters.")
                return

        st.write("### 3. Visualiza√ß√£o dos Clusters")
        df_with_clusters = df_cluster_clean.copy()
        df_with_clusters['Cluster'] = cluster_labels.astype(str)
        st.dataframe(df_with_clusters.head())

        st.write("#### Gr√°fico de Dispers√£o dos Clusters (PCA)")
        if principal_components is not None:
            pca_df = pd.DataFrame(data = principal_components, 
                                  columns = ['Componente Principal 1', 'Componente Principal 2'],
                                  index=df_cluster_clean.index)
            pca_df['Cluster'] = cluster_labels.astype(str)

            fig_scatter, ax_scatter = plt.subplots(figsize=(10, 8))
            sns.scatterplot(
                x='Componente Principal 1', 
                y='Componente Principal 2', 
                hue='Cluster', 
                palette='viridis', 
                data=pca_df, 
                ax=ax_scatter,
                s=100,
                alpha=0.7
            )
            ax_scatter.set_title('Visualiza√ß√£o dos Clusters (PCA)')
            ax_scatter.set_xlabel(f'Componente Principal 1 ({pca_explained_variance_ratio[0]*100:.2f}%)')
            ax_scatter.set_ylabel(f'Componente Principal 2 ({pca_explained_variance_ratio[1]*100:.2f}%)')
            ax_scatter.legend(title='Cluster')
            st.pyplot(fig_scatter)
            plt.close(fig_scatter)
            st.info("Este gr√°fico projeta os dados em duas dimens√µes principais (PCA) para visualizar a separa√ß√£o dos clusters. Os r√≥tulos nos eixos indicam a propor√ß√£o da vari√¢ncia total explicada por cada componente principal.")
        else:
            st.warning("N√£o √© poss√≠vel gerar um gr√°fico de dispers√£o 2D usando PCA. As vari√°veis selecionadas para clustering t√™m menos de 2 dimens√µes. Selecione pelo menos duas vari√°veis num√©ricas.")
    


    if 'cluster_labels_latest' in st.session_state and 'cluster_features_latest' in st.session_state:
        st.write("### 4. Caracter√≠sticas dos Clusters")

        df_with_clusters_for_means = df_cluster_clean.copy()
        # Ensure 'Cluster' column is string type before converting to category
        df_with_clusters_for_means['Cluster'] = st.session_state['cluster_labels_latest'].astype(str)
        st.dataframe(df_with_clusters_for_means.groupby('Cluster')[st.session_state['cluster_features_latest']].mean().round(2))

        if st.button("Adicionar r√≥tulos de Cluster ao DataFrame processado", key="add_cluster_to_df_button"):
            cluster_labels = st.session_state['cluster_labels_latest']
            selected_cols_for_clustering = st.session_state['cluster_features_latest']

            # Convert cluster_labels to string type BEFORE creating the series and filling NaNs
            cluster_series = pd.Series(cluster_labels.astype(str), index=df_cluster_clean.index, name='Cluster_KMeans')

            df_processed_temp = st.session_state.df_processed.copy()
            
            # Reindex, fill NaN with the string, then convert to category
            df_processed_temp['Cluster_KMeans'] = cluster_series.reindex(df_processed_temp.index).fillna('N√£o_Clusterizado').astype('category')
            
            st.session_state.df_processed = df_processed_temp

            st.success("Coluna 'Cluster_KMeans' adicionada ao DataFrame processado na sess√£o.")

def show_exploratory_analysis():
    key_prefix = "ea_"
    st.header("üìä An√°lise Explorat√≥ria de Dados")
    if st.session_state['df_processed'] is None or st.session_state['df_processed'].empty:
        st.warning("‚ö†Ô∏è Dados n√£o carregados ou pr√©-processados. Por favor, complete as etapas anteriores.")
        return

    df_ea = st.session_state['df_processed'].copy()

    st.info("Nesta se√ß√£o, voc√™ pode realizar v√°rias an√°lises explorat√≥rias no seu DataFrame processado. Use os expanders abaixo para selecionar o tipo de an√°lise.")

    with st.expander("üìà Visualiza√ß√£o Geral do DataFrame"):
        st.subheader("Vis√£o Geral do DataFrame Processado")
        st.dataframe(df_ea.head())
        st.write(f"Dimens√µes: {df_ea.shape[0]} linhas, {df_ea.shape[1]} colunas.")

        st.subheader("Informa√ß√µes sobre as Colunas")
        buffer = pd.io.common.StringIO()
        df_ea.info(buf=buffer)
        s = buffer.getvalue()
        st.text(s)

    with st.expander("üìä An√°lise Descritiva dos Dados Num√©ricos"):
        num_cols = df_ea.select_dtypes(include=["number"]).columns.tolist()

        if not num_cols:
            st.info("Nenhuma vari√°vel num√©rica dispon√≠vel.")
        else:
            selected_num_cols = st.multiselect(
                "Selecione as vari√°veis num√©ricas que deseja explorar:",
                options=num_cols,
                default=[],
                key=key_prefix + "desc_num_multiselect"
            )

            if not selected_num_cols:
                st.info("Selecione pelo menos uma vari√°vel.")
            else:
                desc_df = df_ea[selected_num_cols].describe().T
                desc_df["coef_var"] = desc_df["std"] / desc_df["mean"]
                desc_df["amplitude"] = desc_df["max"] - desc_df["min"]
                desc_df["curtose"] = df_ea[selected_num_cols].kurtosis()
                desc_df["assimetria"] = df_ea[selected_num_cols].skew()

                st.markdown("#### Estat√≠sticas Descritivas com Indicadores Ampliados")
                st.dataframe(desc_df)

                st.markdown("#### Diagn√≥stico Interpretativo de Curtose e Assimetria")
                for var in selected_num_cols:
                    skew_val = desc_df.loc[var, "assimetria"]
                    kurt_val = desc_df.loc[var, "curtose"]

                    if abs(skew_val) < 0.5:
                        skew_txt = "distribui√ß√£o aproximadamente sim√©trica"
                    elif skew_val >= 0.5:
                        skew_txt = "distribui√ß√£o assim√©trica √† direita (cauda longa √† direita)"
                    else:
                        skew_txt = "distribui√ß√£o assim√©trica √† esquerda (cauda longa √† esquerda)"

                    if kurt_val < -1:
                        kurt_txt = "distribui√ß√£o platic√∫rtica (achatada)"
                    elif -1 <= kurt_val <= 1:
                        kurt_txt = "curtose pr√≥xima da normal (mesoc√∫rtica)"
                    else:
                        kurt_txt = "distribui√ß√£o leptoc√∫rtica (pontuda)"

                    st.markdown(f"üìå **{var}**: {skew_txt} e {kurt_txt}.")

                st.markdown("#### Histogramas")
                for col in selected_num_cols:
                    st.plotly_chart(px.histogram(df_ea, x=col, nbins=30, title=f"Histograma - {col}"))

                st.markdown("#### Boxplots")
                for col in selected_num_cols:
                    st.plotly_chart(px.box(df_ea, y=col, points="all", title=f"Boxplot - {col}"))


                st.markdown("#### üì¶ Exportar Diagn√≥sticos em .zip")

                def gerar_pacote_diagnosticos():
                    with tempfile.TemporaryDirectory() as tmpdir:
                        txt_path = os.path.join(tmpdir, "diagnosticos.txt")
                        with open(txt_path, "w", encoding="utf-8") as f_txt:
                            for col in selected_num_cols:
                                data = df_ea[col].dropna()

                                fig, axes = plt.subplots(1, 2, figsize=(10, 4))
                                sns.histplot(data, kde=True, ax=axes[0])
                                axes[0].set_title(f"Histograma - {col}")
                                sns.boxplot(x=data, ax=axes[1])
                                axes[1].set_title(f"Boxplot - {col}")
                                plt.tight_layout()

                                fig_path = os.path.join(tmpdir, f"{col}.png")
                                fig.savefig(fig_path)
                                plt.close(fig)

                                skew_val = skew(data)
                                kurt_val = kurtosis(data)

                                if abs(skew_val) < 0.5:
                                    skew_txt = "distribui√ß√£o aproximadamente sim√©trica"
                                elif skew_val > 0.5:
                                    skew_txt = "distribui√ß√£o assim√©trica √† direita (cauda longa √† direita)"
                                else:
                                    skew_txt = "distribui√ß√£o assim√©trica √† esquerda (cauda longa √† esquerda)"

                                if kurt_val < -1:
                                    kurt_txt = "distribui√ß√£o platic√∫rtica (achatada)"
                                elif -1 <= kurt_val <= 1:
                                    kurt_txt = "curtose pr√≥xima da normal (mesoc√∫rtica)"
                                else:
                                    kurt_txt = "distribui√ß√£o leptoc√∫rtica (pontuda)"

                                diag_text = f"üìå {col}:\n- {skew_txt}\n- {kurt_txt}\n\n"
                                f_txt.write(diag_text)

                        zip_path = os.path.join(tmpdir, "diagnosticos.zip")
                        with zipfile.ZipFile(zip_path, "w") as zipf:
                            for filename in os.listdir(tmpdir):
                                zipf.write(os.path.join(tmpdir, filename), arcname=filename)

                        with open(zip_path, "rb") as f:
                            st.download_button(
                                label="‚¨áÔ∏è Baixar pacote ZIP",
                                data=f,
                                file_name="diagnosticos.zip",
                                mime="application/zip"
                            )

                if st.button("Gerar pacote com gr√°ficos e interpreta√ß√µes"):
                    gerar_pacote_diagnosticos()


    with st.expander("üìä An√°lise Descritiva dos Dados Categ√≥ricos"):
        cat_cols = df_ea.select_dtypes(include=["object", "category", "bool"]).columns.tolist()

        if not cat_cols:
            st.info("Nenhuma vari√°vel categ√≥rica dispon√≠vel.")
        else:
            selected_cat_cols = st.multiselect(
                "Selecione as vari√°veis categ√≥ricas que deseja explorar:",
                options=cat_cols,
                default=[],
                key=key_prefix + "desc_cat_multiselect"
            )

            if not selected_cat_cols:
                st.info("Selecione pelo menos uma vari√°vel.")
            else:
                for col in selected_cat_cols:
                    st.markdown(f"### üìå {col}")

                    freq_abs = df_ea[col].value_counts(dropna=False)
                    freq_rel = df_ea[col].value_counts(normalize=True, dropna=False) * 100
                    freq_df = pd.DataFrame({
                        "Frequ√™ncia Absoluta": freq_abs,
                        "Frequ√™ncia Relativa (%)": freq_rel.round(2)
                    })

                    st.dataframe(freq_df)

                    num_unique = df_ea[col].nunique(dropna=False)
                    moda = df_ea[col].mode().iloc[0] if not df_ea[col].mode().empty else "N/A"

                    total = len(df_ea[col])
                    dominant_cat = freq_abs.idxmax()
                    dominant_pct = freq_rel[dominant_cat]

                    if num_unique == 1:
                        interpret = "üìå A vari√°vel √© constante ‚Äî possui apenas uma categoria."
                    elif dominant_pct > 90:
                        interpret = f"üìå A categoria '{dominant_cat}' domina com {dominant_pct:.1f}% dos casos."
                    elif num_unique > 20:
                        interpret = f"üìå A vari√°vel tem alta cardinalidade ({num_unique} categorias)."
                    else:
                        interpret = f"üìå Distribui√ß√£o razoavelmente balanceada com {num_unique} categorias. Moda: '{moda}'."

                    st.info(interpret)
           
    with st.expander("üìä An√°lise de Conting√™ncia e Frequ√™ncia"):
        show_contingency_analysis(df_ea)

    with st.expander("üîó Correla√ß√µes num√©ricas"):
        show_correlation_matrix_interface(df_ea)

    with st.expander("üß™ Testes T (Uma Amostra, Independentes, Pareadas)"):
        show_t_tests(df_ea)

    with st.expander("üìà An√°lise de Vari√¢ncia (ANOVA)"):
        show_anova_analysis(df_ea)

    with st.expander("üîç An√°lise de Cluster (K-Means)"):
        show_clustering_analysis(df_ea)