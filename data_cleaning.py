import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --- Fun√ß√µes Auxiliares para Tratamento de Dados ---
def rename_column_values(df, col, mapping_dict):
    df_copy = df.copy()
    if col in df_copy.columns:
        # Use .copy() on the column to avoid SettingWithCopyWarning if original df was a slice
        df_copy[col] = df_copy[col].replace(mapping_dict)
    return df_copy

def detect_outliers_iqr(df, col, factor=1.5):
    # Ensure the column is numeric before calculating quantiles
    if not pd.api.types.is_numeric_dtype(df[col]):
        return pd.Index([]) # Return empty index if not numeric
    
    # Drop NaNs for quantile calculation to avoid errors
    numeric_series = df[col].dropna()
    if numeric_series.empty:
        return pd.Index([]) # Return empty index if no valid numeric data

    Q1 = numeric_series.quantile(0.25)
    Q3 = numeric_series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - factor * IQR
    upper_bound = Q3 + factor * IQR
    return df[(df[col] < lower_bound) | (df[col] > upper_bound)].index

def remove_outliers_iqr(df, cols, factor=1.5):
    df_clean = df.copy()
    outlier_indices = set()
    for col in cols:
        if pd.api.types.is_numeric_dtype(df_clean[col]):
            if not df_clean[col].dropna().empty:
                outlier_indices.update(detect_outliers_iqr(df_clean, col, factor))
    if outlier_indices:
        return df_clean.drop(index=list(outlier_indices))
    return df_clean

def winsorize_outliers(df, cols, factor=1.5):
    df_copy = df.copy()
    for col in cols:
        if pd.api.types.is_numeric_dtype(df_copy[col]):
            if not df_copy[col].dropna().empty:
                Q1 = df_copy[col].quantile(0.25)
                Q3 = df_copy[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - factor * IQR
                upper_bound = Q3 + factor * IQR
                df_copy[col] = np.clip(df_copy[col], lower_bound, upper_bound)
    return df_copy

def replace_outliers_with_median(df, cols, factor=1.5):
    df_copy = df.copy()
    for col in cols:
        if pd.api.types.is_numeric_dtype(df_copy[col]):
            if not df_copy[col].dropna().empty:
                Q1 = df_copy[col].quantile(0.25)
                Q3 = df_copy[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - factor * IQR
                upper_bound = Q3 + factor * IQR
                median_val = df_copy[col].median()
                outliers = (df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)
                df_copy.loc[outliers, col] = median_val
    return df_copy

def handle_outliers(df, cols, method, factor=1.5):
    if method == "Remover linhas":
        return remove_outliers_iqr(df, cols, factor)
    elif method == "Winsoriza√ß√£o":
        return winsorize_outliers(df, cols, factor)
    elif method == "Substituir por mediana":
        return replace_outliers_with_median(df, cols, factor)
    return df # Return original df if no valid method

def remove_missing_rows(df, cols):
    existing_cols = [col for col in cols if col in df.columns]
    if existing_cols:
        return df.dropna(subset=existing_cols)
    return df

def impute_missing_mean(df, cols):
    df_copy = df.copy()
    for col in cols:
        # Check if numeric and has NaNs
        if pd.api.types.is_numeric_dtype(df_copy[col]) and df_copy[col].isnull().any():
            mean_val = df_copy[col].mean()
            df_copy[col] = df_copy[col].fillna(mean_val)
    return df_copy

def impute_missing_median(df, cols):
    df_copy = df.copy()
    for col in cols:
        # Check if numeric and has NaNs
        if pd.api.types.is_numeric_dtype(df_copy[col]) and df_copy[col].isnull().any():
            median_val = df_copy[col].median()
            df_copy[col] = df_copy[col].fillna(median_val)
    return df_copy

def impute_missing_fixed(df, cols, fixed_value):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and df_copy[col].isnull().any():
            df_copy[col] = df_copy[col].fillna(fixed_value)
    return df_copy

def impute_missing_mode(df, cols):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and df_copy[col].isnull().any():
            # Check if mode can be calculated (not empty after dropping NaNs)
            if not df_copy[col].dropna().empty:
                mode_val = df_copy[col].mode()[0] # .mode() returns a Series, take the first
                df_copy[col] = df_copy[col].fillna(mode_val)
    return df_copy

def interpolate_missing(df, cols):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
            df_copy[col] = df_copy[col].interpolate(method='linear', limit_direction='both')
    return df_copy

def standardize_columns(df, cols):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
            # Only standardize if there are non-NaN values
            if not df_copy[col].dropna().empty:
                mean = df_copy[col].mean()
                std = df_copy[col].std()
                if std != 0:
                    df_copy[f"{col}_z"] = (df_copy[col] - mean) / std
                else:
                    df_copy[f"{col}_z"] = 0 # If std is 0, all values are the same, so Z-score is 0
            else:
                df_copy[f"{col}_z"] = df_copy[col] # Keep NaNs if original is all NaNs
    return df_copy

def normalize_columns(df, cols):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
            # Only normalize if there are non-NaN values
            if not df_copy[col].dropna().empty:
                min_val = df_copy[col].min()
                max_val = df_copy[col].max()
                if max_val - min_val != 0:
                    df_copy[f"{col}_minmax"] = (df_copy[col] - min_val) / (max_val - min_val)
                else:
                    df_copy[f"{col}_minmax"] = 0 # If min=max, all values are the same, so Min-Max is 0
            else:
                df_copy[f"{col}_minmax"] = df_copy[col] # Keep NaNs if original is all NaNs
    return df_copy

def log_transform_columns(df, cols):
    df_copy = df.copy()
    for col in cols:
        if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
            # Only transform if there are non-NaN values
            if not df_copy[col].dropna().empty:
                # Use .clip(lower=0) to handle potential negative values before log1p
                df_copy[f"{col}_log"] = np.log1p(df_copy[col].clip(lower=0))
            else:
                df_copy[f"{col}_log"] = df_copy[col] # Keep NaNs if original is all NaNs
    return df_copy

# --- Interface Streamlit para pr√©-processamento (fun√ß√£o principal) ---
def show_preprocessing_interface():
    # st.title("üßπ Pr√©-processamento de Dados") # Title can be placed in main app.py
    st.info("Esta se√ß√£o permite selecionar as colunas para o seu DataFrame de trabalho, aplicar pr√©-processamento e ajustar os tipos de dados.")

    # --- Inicializa√ß√£o das chaves de sess√£o ---
    # Initialize all session state variables at the beginning for robustness
    if 'selected_columns_for_df_processed' not in st.session_state:
        st.session_state['selected_columns_for_df_processed'] = []
    if 'df_processed' not in st.session_state:
        st.session_state['df_processed'] = pd.DataFrame() # Initialize as an empty DataFrame
    if 'last_preprocessing_log' not in st.session_state:
        st.session_state['last_preprocessing_log'] = []
    if 'preprocessing_applied_flag' not in st.session_state:
        st.session_state['preprocessing_applied_flag'] = False
    if 'reset_selection_trigger' not in st.session_state:
        st.session_state['reset_selection_trigger'] = 0
    if 'selected_cols_for_ops_multiselect' not in st.session_state:
        st.session_state['selected_cols_for_ops_multiselect'] = []
    if "selected_col_to_convert" not in st.session_state:
        st.session_state.selected_col_to_convert = "Nenhum"
    if "selected_target_dtype" not in st.session_state:
        st.session_state.selected_target_dtype = "Nenhum"
    if "datetime_format_input" not in st.session_state:
        st.session_state.datetime_format_input = ""
    if "duplicated_col_name" not in st.session_state:
        st.session_state["duplicated_col_name"] = None
    if 'select_all_initial_cols_checkbox' not in st.session_state:
        st.session_state['select_all_initial_cols_checkbox'] = False
    if 'select_all_for_ops_checkbox' not in st.session_state: # Ensure this is initialized
        st.session_state['select_all_for_ops_checkbox'] = False


    # --- Verifica√ß√£o de DataFrame Carregado ---
    if 'df_original' not in st.session_state or st.session_state.df_original is None or st.session_state.df_original.empty:
        st.warning("Nenhum dado original dispon√≠vel. Por favor, carregue um arquivo no menu lateral para come√ßar.")
        st.session_state['df_processed'] = pd.DataFrame() # Ensure df_processed is always a DataFrame
        st.session_state['selected_columns_for_df_processed'] = []
        st.session_state['last_preprocessing_log'] = []
        return # Exit if no original data

    # --- Se√ß√£o 1: Sele√ß√£o de Colunas para o DataFrame de Trabalho ---
    with st.expander("1. Sele√ß√£o de Colunas para o DataFrame de Trabalho", expanded=True):
        st.markdown("Selecione as colunas do seu **DataFrame Original** que voc√™ deseja incluir no **DataFrame de Trabalho (`df_processed`)**.")

        all_original_columns = st.session_state['df_original'].columns.tolist()

        def apply_column_selection_callback():
            current_selection = st.session_state.get('multiselect_initial_cols', [])
            st.session_state['selected_columns_for_df_processed'] = current_selection

            if current_selection:
                st.session_state['df_processed'] = st.session_state['df_original'][current_selection].copy()
                st.session_state['last_preprocessing_log'] = [f"DataFrame de trabalho inicializado com {len(current_selection)} colunas selecionadas do original."]
                st.session_state['preprocessing_applied_flag'] = True
                # Reset operations selections when df_processed columns change
                st.session_state['selected_cols_for_ops_multiselect'] = []
                st.session_state['select_all_for_ops_checkbox'] = False # Reset the ops select all checkbox
                st.session_state['selected_col_to_convert'] = "Nenhum"
                st.session_state['selected_target_dtype'] = "Nenhum"
                st.session_state.duplicated_col_name = None # Reset duplicated column
            else:
                st.info("Nenhuma coluna selecionada para o DataFrame de trabalho. O DataFrame de trabalho foi redefinido para vazio.")
                st.session_state['df_processed'] = pd.DataFrame() # Ensure it's an empty DataFrame
                st.session_state['last_preprocessing_log'] = ["Nenhuma coluna selecionada. DataFrame de trabalho vazio."]
                st.session_state['preprocessing_applied_flag'] = False
                st.session_state['selected_cols_for_ops_multiselect'] = []
                st.session_state['select_all_for_ops_checkbox'] = False
                st.session_state['selected_col_to_convert'] = "Nenhum"
                st.session_state['selected_target_dtype'] = "Nenhum"
                st.session_state.duplicated_col_name = None # Reset duplicated column

            st.session_state['reset_selection_trigger'] += 1 # Trigger a refresh for multiselect keys
            st.rerun()

        # Determine if 'select all' checkbox should be checked by default
        current_select_all_initial = (
            len(st.session_state['selected_columns_for_df_processed']) == len(all_original_columns)
            and len(all_original_columns) > 0
        )
        
        # Ensure checkbox value matches the current state
        # st.session_state['select_all_initial_cols_checkbox'] = current_select_all_initial # This line might cause issues with on_change if directly manipulated before the widget

        def toggle_select_all_initial_cols():
            if st.session_state.select_all_initial_cols_checkbox:
                st.session_state['multiselect_initial_cols'] = all_original_columns.copy()
            else:
                st.session_state['multiselect_initial_cols'] = []
            apply_column_selection_callback() # Call the apply function to update df_processed and other states
            
        st.checkbox(
            "Selecionar/Desselecionar Todas as Colunas Originais",
            value=current_select_all_initial,
            key="select_all_initial_cols_checkbox",
            on_change=toggle_select_all_initial_cols
        )

        selected_cols_multiselect = st.multiselect(
            "Colunas a serem inclu√≠das no DataFrame de trabalho:",
            options=all_original_columns,
            default=st.session_state['selected_columns_for_df_processed'],
            key="multiselect_initial_cols"
        )
        
        st.button("Aplicar Sele√ß√£o de Colunas para DataFrame de Trabalho", on_click=apply_column_selection_callback, key="apply_df_creation_btn")

    st.markdown("---")

    # --- Se√ß√£o 2: Aplica√ß√£o de Pr√©-processamento e Transforma√ß√µes ---
    # Moved toggle_select_all_ops_cols and its checkbox OUTSIDE the form to resolve StreamlitInvalidFormCallbackError
    # This function is now called by the checkbox which is outside the form.
    def toggle_select_all_ops_cols():
        # Ensure df_processed is not empty before attempting to get columns
        if st.session_state['df_processed'] is not None and not st.session_state['df_processed'].empty:
            current_df_processed_columns = st.session_state['df_processed'].columns.tolist()
            if st.session_state.select_all_for_ops_checkbox:
                st.session_state['selected_cols_for_ops_multiselect'] = current_df_processed_columns.copy()
            else:
                st.session_state['selected_cols_for_ops_multiselect'] = []
        else:
            st.session_state['selected_cols_for_ops_multiselect'] = [] # If df_processed is empty, clear selection

    with st.expander("2. Aplica√ß√£o de Pr√©-processamento e Transforma√ß√µes", expanded=True):
        st.markdown("Selecione as colunas do **DataFrame de Trabalho (`df_processed`)** nas quais voc√™ deseja aplicar opera√ß√µes de limpeza e transforma√ß√£o.")

        # Crucial fix: Move this checkbox OUTSIDE the form
        if st.session_state['df_processed'] is not None and not st.session_state['df_processed'].empty:
            current_df_processed_columns = st.session_state['df_processed'].columns.tolist()
            current_select_all_ops = (
                len(st.session_state['selected_cols_for_ops_multiselect']) == len(current_df_processed_columns)
                and len(current_df_processed_columns) > 0
            )
            st.checkbox(
                "Selecionar/Desselecionar Todas as Colunas do DataFrame de Trabalho para Pr√©-processamento",
                value=current_select_all_ops, # Use the dynamically updated value
                key="select_all_for_ops_checkbox",
                on_change=toggle_select_all_ops_cols
            )
        else:
            # If df_processed is empty, display a disabled checkbox or just a placeholder message
            st.info("Para selecionar colunas para pr√©-processamento, primeiro crie o DataFrame de Trabalho na Se√ß√£o 1.")

        # The form itself starts here
        with st.form('form_preprocessing_section'):
            # This check remains important for displaying appropriate messages and disabling the submit button.
            if st.session_state['df_processed'] is None or st.session_state['df_processed'].empty:
                st.warning("DataFrame de trabalho ainda n√£o criado ou est√° vazio. Por favor, fa√ßa a 'Sele√ß√£o de Colunas para o DataFrame de Trabalho' acima primeiro.")
                # Render a disabled submit button to satisfy Streamlit's form requirement
                submit_preproc = st.form_submit_button("Aplicar Limpeza e Transforma√ß√µes", disabled=True)
            else:
                st.markdown("### Etapas de Pr√©-processamento")
                current_df_processed_columns = st.session_state['df_processed'].columns.tolist()
                
                # The multiselect remains inside the form
                cols_to_apply_preprocessing = st.multiselect(
                    "Selecione as colunas do DataFrame de Trabalho para aplicar pr√©-processamento:",
                    options=current_df_processed_columns,
                    default=st.session_state['selected_cols_for_ops_multiselect'],
                    key=f"cols_to_apply_preprocessing_multiselect_form_{st.session_state['reset_selection_trigger']}" # Key change for reset
                )
                # Ensure session state reflects current multiselect value immediately
                if st.session_state['selected_cols_for_ops_multiselect'] != cols_to_apply_preprocessing:
                    st.session_state['selected_cols_for_ops_multiselect'] = cols_to_apply_preprocessing

                # Filter columns based on type for specific operations
                selected_numeric_cols_for_ops = [col for col in cols_to_apply_preprocessing if pd.api.types.is_numeric_dtype(st.session_state['df_processed'][col])]
                selected_non_numeric_cols_for_ops = [col for col in cols_to_apply_preprocessing if not pd.api.types.is_numeric_dtype(st.session_state['df_processed'][col])]

                st.subheader("Tratamento de Valores Faltantes")
                missing_method = st.selectbox(
                    "M√©todo para tratamento de valores faltantes (missing values):",
                    options=["Nenhum", "Remover linhas", "Imputar com m√©dia", "Imputar com mediana", "Imputar com moda", "Imputar valor fixo", "Interpolar"],
                    key="missing_method_select"
                )
                fixed_value_imputation = None
                fixed_value_imputation_str = None
                if missing_method == "Imputar valor fixo":
                    # Ensure visibility of inputs based on selected columns
                    if selected_numeric_cols_for_ops:
                        fixed_value_imputation = st.number_input("Valor fixo para imputar em colunas NUM√âRICAS:", value=0.0, key="fixed_num_value_input")
                    else:
                        fixed_value_imputation = None # Clear if no numeric cols
                    if selected_non_numeric_cols_for_ops:
                        fixed_value_imputation_str = st.text_input("Valor fixo para imputar em colunas N√ÉO NUM√âRICAS:", value="Desconhecido", key="fixed_cat_value_input")
                    else:
                        fixed_value_imputation_str = None # Clear if no non-numeric cols
                    if not selected_numeric_cols_for_ops and not selected_non_numeric_cols_for_ops:
                        st.info("Nenhuma coluna selecionada para imputa√ß√£o de valor fixo.")

                st.subheader("Tratamento de Outliers")
                outlier_method = st.selectbox(
                    "M√©todo para tratamento de outliers (apenas para colunas num√©ricas selecionadas):",
                    options=["Nenhum", "Remover linhas", "Winsoriza√ß√£o", "Substituir por mediana"],
                    key="outlier_method_select"
                )
                iqr_factor = 1.5
                if outlier_method != "Nenhum":
                    if selected_numeric_cols_for_ops:
                        iqr_factor = st.slider("Fator multiplicador do IQR para definir outliers:", 1.0, 3.0, 1.5, key="iqr_factor_slider")
                    else:
                        st.info("Nenhuma coluna num√©rica selecionada para tratamento de outliers.")

                st.subheader("Transforma√ß√µes (Criar Novas Colunas)")
                st.info("Estas opera√ß√µes criam novas colunas no DataFrame de trabalho com o sufixo indicado.")
                standardize = st.checkbox("Aplicar padroniza√ß√£o (Z-Score) (sufixo: _z)", key="standardize_checkbox")
                normalize = st.checkbox("Aplicar normaliza√ß√£o (Min-Max) (sufixo: _minmax)", key="normalize_checkbox")
                log_transform_flag = st.checkbox("Aplicar transforma√ß√£o logar√≠tmica (log1p) (sufixo: _log)", key="log_transform_checkbox")
                
                # Single submit button, always present within the form if the outer condition is met
                submit_preproc = st.form_submit_button("Aplicar Limpeza e Transforma√ß√µes")
                
                if submit_preproc:
                    if st.session_state.df_original is None or st.session_state.df_original.empty:
                        st.error("N√£o h√° dados originais para processar. Por favor, carregue um arquivo.")
                        st.session_state['last_preprocessing_log'] = ["Erro: Nenhum dado original para processar."]
                        st.session_state['preprocessing_applied_flag'] = False
                        st.rerun()
                        return
                    
                    # Check df_processed again, as it might have become empty after previous operations (e.g., initial column selection)
                    if st.session_state['df_processed'].empty:
                        st.warning("DataFrame de trabalho est√° vazio. Nenhuma opera√ß√£o de pr√©-processamento ser√° aplicada. Por favor, fa√ßa a sele√ß√£o inicial de colunas.")
                        st.session_state['last_preprocessing_log'] = ["Aviso: DataFrame de trabalho vazio. Nenhuma opera√ß√£o aplicada."]
                        st.session_state['preprocessing_applied_flag'] = False
                        st.rerun()
                        return

                    processing_temp_df = st.session_state['df_processed'].copy()
                    operations_performed = False
                    processing_log = []

                    cols_to_apply_preprocessing_current = st.session_state.get('selected_cols_for_ops_multiselect', [])

                    # 1. Tratamento de Missing Values
                    if missing_method != "Nenhum" and cols_to_apply_preprocessing_current:
                        st.info(f"Aplicando tratamento de valores faltantes: '{missing_method}'...")
                        for col in cols_to_apply_preprocessing_current:
                            if col not in processing_temp_df.columns:
                                processing_log.append(f"Coluna '{col}' n√£o encontrada no DataFrame de trabalho para tratamento de NaN. Pulando.")
                                continue

                            if processing_temp_df[col].isnull().any():
                                operations_performed = True
                                if pd.api.types.is_numeric_dtype(processing_temp_df[col]):
                                    if missing_method == "Remover linhas":
                                        rows_before = len(processing_temp_df)
                                        processing_temp_df = remove_missing_rows(processing_temp_df, [col])
                                        rows_after = len(processing_temp_df)
                                        if rows_before > rows_after:
                                            processing_log.append(f"Removidas {rows_before - rows_after} linhas com NaN em '{col}'.")
                                    elif missing_method == "Imputar com m√©dia":
                                        processing_temp_df = impute_missing_mean(processing_temp_df, [col])
                                        processing_log.append(f"NaNs em '{col}' imputados com a m√©dia.")
                                    elif missing_method == "Imputar com mediana":
                                        processing_temp_df = impute_missing_median(processing_temp_df, [col])
                                        processing_log.append(f"NaNs em '{col}' imputados com a mediana.")
                                    elif missing_method == "Imputar com moda":
                                        processing_temp_df = impute_missing_mode(processing_temp_df, [col])
                                        processing_log.append(f"NaNs em '{col}' imputados com a moda.")
                                    elif missing_method == "Imputar valor fixo" and fixed_value_imputation is not None:
                                        processing_temp_df = impute_missing_fixed(processing_temp_df, [col], fixed_value_imputation)
                                        processing_log.append(f"NaNs em '{col}' imputados com valor fixo ({fixed_value_imputation}).")
                                    elif missing_method == "Interpolar":
                                        processing_temp_df = interpolate_missing(processing_temp_df, [col])
                                        processing_log.append(f"NaNs em '{col}' imputados por interpola√ß√£o.")
                                else: # Non-numeric columns
                                    if missing_method == "Imputar com moda":
                                        processing_temp_df = impute_missing_mode(processing_temp_df, [col])
                                        processing_log.append(f"NaNs em '{col}' (n√£o num√©rica) imputados com a moda.")
                                    elif missing_method == "Imputar valor fixo" and fixed_value_imputation_str is not None:
                                        processing_temp_df = impute_missing_fixed(processing_temp_df, [col], fixed_value_imputation_str)
                                        processing_log.append(f"NaNs em '{col}' (n√£o num√©rica) imputados com valor fixo ('{fixed_value_imputation_str}').")
                                    else:
                                        processing_log.append(f"Estrat√©gia '{missing_method}' n√£o aplic√°vel ou valor n√£o fornecido para '{col}' (n√£o num√©rica).")
                            else:
                                processing_log.append(f"Coluna '{col}' n√£o tem valores faltantes.")
                    elif missing_method != "Nenhum" and not cols_to_apply_preprocessing_current:
                        processing_log.append("Estrat√©gia de tratamento de NaN selecionada, mas nenhuma coluna para tratamento foi escolhida na Se√ß√£o 2.")
                    elif missing_method == "Nenhum":
                        processing_log.append("Nenhum tratamento de valores faltantes selecionado.")


                    # 2. Tratamento de Outliers
                    selected_numeric_cols_for_ops_current = [col for col in cols_to_apply_preprocessing_current if pd.api.types.is_numeric_dtype(processing_temp_df[col])]

                    if outlier_method != "Nenhum" and selected_numeric_cols_for_ops_current:
                        st.info(f"Aplicando tratamento de outliers: '{outlier_method}' (Fator IQR: {iqr_factor})...")
                        # For remove rows, apply once to the whole df for selected columns
                        if outlier_method == "Remover linhas":
                            initial_rows = len(processing_temp_df)
                            processing_temp_df = handle_outliers(processing_temp_df, selected_numeric_cols_for_ops_current, outlier_method, iqr_factor)
                            if len(processing_temp_df) < initial_rows:
                                processing_log.append(f"Removidas {initial_rows - len(processing_temp_df)} linhas com outliers em colunas selecionadas ({outlier_method}).")
                                operations_performed = True
                            else:
                                processing_log.append(f"Outliers em colunas selecionadas ({outlier_method}) solicitados, mas nenhuma linha removida.")
                        else: # Winsoriza√ß√£o ou Substituir por mediana
                            for col in selected_numeric_cols_for_ops_current:
                                original_col_data = processing_temp_df[col].copy()
                                # Use a temporary DataFrame with only the column to be processed
                                temp_col_df = processing_temp_df[[col]].copy()
                                processed_col_df = handle_outliers(temp_col_df, [col], outlier_method, iqr_factor)
                                
                                # Check if the column actually changed
                                if not original_col_data.equals(processed_col_df[col]):
                                    processing_temp_df[col] = processed_col_df[col]
                                    processing_log.append(f"Outliers em '{col}' tratados por '{outlier_method}'.")
                                    operations_performed = True
                                else:
                                    processing_log.append(f"Outliers em '{col}' tratados por '{outlier_method}' solicitados, mas nenhuma altera√ß√£o detectada.")
                    elif outlier_method != "Nenhum" and not selected_numeric_cols_for_ops_current:
                        processing_log.append("Estrat√©gia de tratamento de outliers selecionada, mas nenhuma coluna num√©rica eleg√≠vel para tratamento foi escolhida na Se√ß√£o 2.")
                    elif outlier_method == "Nenhum":
                        processing_log.append("Nenhum tratamento de outliers selecionado.")

                    # 3. Transforma√ß√µes (Padroniza√ß√£o, Normaliza√ß√£o, Log)
                    current_numeric_cols_for_transforms = [col for col in cols_to_apply_preprocessing_current if col in processing_temp_df.columns and pd.api.types.is_numeric_dtype(processing_temp_df[col])]

                    if standardize and current_numeric_cols_for_transforms:
                        st.info("Aplicando padroniza√ß√£o (Z-Score)...")
                        initial_cols = processing_temp_df.columns.tolist()
                        processing_temp_df = standardize_columns(processing_temp_df, current_numeric_cols_for_transforms)
                        if set(processing_temp_df.columns) != set(initial_cols): # Check if new columns were added
                            cols_added_std = [c for c in processing_temp_df.columns if c not in initial_cols and c.endswith('_z')]
                            processing_log.append(f"Padroniza√ß√£o (Z-Score) aplicada √†s colunas: {', '.join(cols_added_std)} (novas colunas com sufixo '_z').")
                            operations_performed = True
                        else:
                            processing_log.append("Padroniza√ß√£o solicitada, mas nenhuma nova coluna _z foi criada ou n√£o houve altera√ß√£o.")
                    elif standardize and not current_numeric_cols_for_transforms:
                        processing_log.append("Padroniza√ß√£o (Z-Score) solicitada, mas nenhuma coluna num√©rica eleg√≠vel foi selecionada na Se√ß√£o 2.")

                    if normalize and current_numeric_cols_for_transforms:
                        st.info("Aplicando normaliza√ß√£o (Min-Max)...")
                        initial_cols = processing_temp_df.columns.tolist()
                        processing_temp_df = normalize_columns(processing_temp_df, current_numeric_cols_for_transforms)
                        if set(processing_temp_df.columns) != set(initial_cols): # Check if new columns were added
                            cols_added_norm = [c for c in processing_temp_df.columns if c not in initial_cols and c.endswith('_minmax')]
                            processing_log.append(f"Normaliza√ß√£o (Min-Max) aplicada √†s colunas: {', '.join(cols_added_norm)} (novas colunas com sufixo '_minmax').")
                            operations_performed = True
                        else:
                            processing_log.append("Normaliza√ß√£o solicitada, mas nenhuma nova coluna _minmax foi criada ou n√£o houve altera√ß√£o.")
                    elif normalize and not current_numeric_cols_for_transforms:
                        processing_log.append("Normaliza√ß√£o (Min-Max) solicitada, mas nenhuma coluna num√©rica eleg√≠vel foi selecionada na Se√ß√£o 2.")

                    if log_transform_flag and current_numeric_cols_for_transforms:
                        st.info("Aplicando transforma√ß√£o logar√≠tmica (log1p)...")
                        initial_cols = processing_temp_df.columns.tolist()
                        processing_temp_df = log_transform_columns(processing_temp_df, current_numeric_cols_for_transforms)
                        if set(processing_temp_df.columns) != set(initial_cols): # Check if new columns were added
                            cols_added_log = [c for c in processing_temp_df.columns if c not in initial_cols and c.endswith('_log')]
                            processing_log.append(f"Transforma√ß√£o logar√≠tmica (log1p) aplicada √†s colunas: {', '.join(cols_added_log)} (novas colunas com sufixo '_log').")
                            operations_performed = True
                        else:
                            processing_log.append("Transforma√ß√£o logar√≠tmica solicitada, mas nenhuma nova coluna _log foi criada ou n√£o houve altera√ß√£o.")
                    elif log_transform_flag and not current_numeric_cols_for_transforms:
                        processing_log.append("Transforma√ß√£o logar√≠tmica solicitada, mas nenhuma coluna num√©rica eleg√≠vel foi selecionada na Se√ß√£o 2.")
                    
                    if not operations_performed:
                        processing_log.append("Nenhuma opera√ß√£o de pr√©-processamento foi aplicada.")

                    st.session_state['df_processed'] = processing_temp_df
                    st.session_state['last_preprocessing_log'] = processing_log
                    st.session_state['preprocessing_applied_flag'] = True if operations_performed else False
                    st.rerun()

    st.markdown("---")

    # --- Se√ß√£o 3: Convers√£o de Tipos de Dados ---
    with st.expander("3. Convers√£o de Tipos de Dados", expanded=False):
        st.info("Ajuste o tipo de dado de colunas espec√≠ficas.")

        col_to_convert = "Nenhum"
        if st.session_state['df_processed'] is None or st.session_state['df_processed'].empty:
            st.warning("DataFrame de trabalho ainda n√£o criado ou est√° vazio. Por favor, fa√ßa a 'Sele√ß√£o de Colunas para o DataFrame de Trabalho' acima primeiro.")
        else:
            current_df_processed_columns = st.session_state['df_processed'].columns.tolist()
            if current_df_processed_columns:
                col_to_convert = st.selectbox("Selecione uma coluna para convers√£o de tipo:",
                                                ["Nenhum"] + current_df_processed_columns,
                                                key="convert_col_select")
                # Update session state when selectbox value changes
                if st.session_state.selected_col_to_convert != col_to_convert:
                    st.session_state.selected_col_to_convert = col_to_convert
                    st.session_state.selected_target_dtype = "Nenhum" # Reset target type
                    st.session_state.datetime_format_input = ""

                current_dtype = None
                if col_to_convert != "Nenhum" and col_to_convert in st.session_state['df_processed'].columns:
                    current_dtype = st.session_state['df_processed'][col_to_convert].dtype
                    st.write(f"Tipo atual da coluna '{col_to_convert}': `{current_dtype}`")

                target_dtype_options = ["Nenhum", "int", "float", "datetime", "category", "str (object)"]
                target_dtype = "Nenhum"
                if col_to_convert != "Nenhum":
                    target_dtype = st.selectbox(
                        f"Converter '{col_to_convert}' para:",
                        target_dtype_options,
                        # Set default value based on session state, with a fallback to "Nenhum"
                        index=target_dtype_options.index(st.session_state.selected_target_dtype) if st.session_state.selected_target_dtype in target_dtype_options else 0,
                        key=f"target_dtype_{col_to_convert}" # Use column name in key to ensure unique widget per column
                    )
                    # Update session state when target type changes
                    if st.session_state.selected_target_dtype != target_dtype:
                        st.session_state.selected_target_dtype = target_dtype
                        # Clear datetime format if not converting to datetime
                        if target_dtype != "datetime":
                            st.session_state.datetime_format_input = ""


                    if target_dtype == "datetime":
                        st.info("O Pandas tentar√° inferir o formato da data automaticamente. Forne√ßa um formato se a infer√™ncia falhar (ex: %Y-%m-%d, %d/%m/%Y).")
                        st.session_state.datetime_format_input = st.text_input(
                            "Formato da data (opcional, ex: %Y-%m-%d):",
                            value=st.session_state.datetime_format_input,
                            key="datetime_format_input_text"
                        )
                    # No else needed here, as datetime_format_input is cleared when target_dtype changes

            # Button for Type Conversion
            if st.button("Aplicar Convers√£o de Tipos", key="apply_type_conversion_btn"):
                if st.session_state.df_original is None or st.session_state.df_original.empty:
                    st.error("N√£o h√° dados originais para processar. Por favor, carregue um arquivo.")
                    st.session_state['last_preprocessing_log'] = ["Erro: Nenhum dado original para processar."]
                    st.session_state['preprocessing_applied_flag'] = False
                    st.rerun()
                    return
                
                if st.session_state['df_processed'].empty:
                    st.warning("DataFrame de trabalho est√° vazio. Nenhuma convers√£o de tipo ser√° aplicada. Por favor, fa√ßa a sele√ß√£o inicial de colunas.")
                    st.session_state['last_preprocessing_log'] = ["Aviso: DataFrame de trabalho vazio. Nenhuma convers√£o de tipo aplicada."]
                    st.session_state['preprocessing_applied_flag'] = False
                    st.rerun()
                    return
                
                processing_temp_df = st.session_state['df_processed'].copy()
                operations_performed = False
                processing_log = []

                col_to_convert_current = st.session_state.get('selected_col_to_convert', "Nenhum")
                target_dtype_current = st.session_state.get('selected_target_dtype', "Nenhum")
                datetime_format_current = st.session_state.get('datetime_format_input', "")

                if col_to_convert_current != "Nenhum" and col_to_convert_current in processing_temp_df.columns and target_dtype_current != "Nenhum":
                    operations_performed = True
                    try:
                        if target_dtype_current == "int":
                            # Use 'Int64' for nullable integer type to handle NaNs correctly
                            processing_temp_df[col_to_convert_current] = pd.to_numeric(processing_temp_df[col_to_convert_current], errors='coerce').astype('Int64')
                            processing_log.append(f"Coluna '{col_to_convert_current}' convertida para tipo inteiro ('Int64').")
                        elif target_dtype_current == "float":
                            processing_temp_df[col_to_convert_current] = pd.to_numeric(processing_temp_df[col_to_convert_current], errors='coerce')
                            processing_log.append(f"Coluna '{col_to_convert_current}' convertida para tipo float.")
                        elif target_dtype_current == "datetime":
                            processing_temp_df[col_to_convert_current] = pd.to_datetime(processing_temp_df[col_to_convert_current], errors='coerce', format=datetime_format_current if datetime_format_current else None)
                            processing_log.append(f"Coluna '{col_to_convert_current}' convertida para tipo datetime.")
                        elif target_dtype_current == "category":
                            processing_temp_df[col_to_convert_current] = processing_temp_df[col_to_convert_current].astype('category')
                            processing_log.append(f"Coluna '{col_to_convert_current}' convertida para tipo categ√≥rico.")
                        elif target_dtype_current == "str (object)":
                            processing_temp_df[col_to_convert_current] = processing_temp_df[col_to_convert_current].astype(str)
                            processing_log.append(f"Coluna '{col_to_convert_current}' convertida para tipo string (object).")
                        else:
                            processing_log.append(f"Nenhuma convers√£o de tipo aplicada para '{col_to_convert_current}'.")
                    except Exception as e:
                        processing_log.append(f"Erro ao converter a coluna '{col_to_convert_current}' para '{target_dtype_current}': {e}")
                        
                elif col_to_convert_current != "Nenhum" and target_dtype_current == "Nenhum":
                    processing_log.append(f"Coluna '{col_to_convert_current}' selecionada para convers√£o, mas nenhum tipo de destino foi escolhido.")
                elif col_to_convert_current == "Nenhum" and target_dtype_current != "Nenhum":
                    processing_log.append(f"Tipo de destino '{target_dtype_current}' escolhido, mas nenhuma coluna selecionada para convers√£o.")
                else:
                    processing_log.append("Nenhuma coluna ou tipo de destino selecionado para convers√£o.")
                
                st.session_state['df_processed'] = processing_temp_df
                st.session_state['last_preprocessing_log'] = processing_log
                st.session_state['preprocessing_applied_flag'] = True if operations_performed else False
                st.rerun()

    # --- Se√ß√£o 4: Duplicar Coluna e Renomear Valores ---
    with st.expander("4. Duplicar Coluna e Renomear Valores", expanded=False):
        st.info("Voc√™ pode duplicar uma coluna e renomear seus valores na nova coluna. As altera√ß√µes s√≥ ser√£o aplicadas ap√≥s clicar no bot√£o.")

        if st.session_state['df_processed'] is not None and not st.session_state['df_processed'].empty:
            cols = st.session_state['df_processed'].columns.tolist()
            col_to_duplicate = st.selectbox("Selecione a coluna que deseja duplicar:", ["Nenhum"] + cols, key="duplicate_col_select")

            # Initialize new_col_name for consistent behavior
            default_new_col_name = f"{col_to_duplicate}_copy" if col_to_duplicate != "Nenhum" else "nova_coluna"
            new_col_name = st.text_input("Nome da nova coluna (duplicada):", value=default_new_col_name, key="new_col_name_input")

            if col_to_duplicate != "Nenhum":
                # Check for existing column name only when duplicating
                if new_col_name in st.session_state['df_processed'].columns and new_col_name != default_new_col_name: # Allow default name to be suggested
                    st.warning("J√° existe uma coluna com esse nome. Escolha um nome diferente.")
                elif st.button("Duplicar Coluna", key="duplicate_col_btn"):
                    # Clear previous state related to renaming if a new duplication occurs
                    # This helps avoid confusion if user duplicates multiple times
                    if st.session_state.get("duplicated_col_name") and st.session_state["duplicated_col_name"] != new_col_name:
                        st.session_state.pop(f"rename_map_{st.session_state['duplicated_col_name']}", None)
                        # Also clear old rename_value_* keys if they were for a different column
                        keys_to_clear = [k for k in list(st.session_state.keys()) if k.startswith("rename_value_")]
                        for k in keys_to_clear:
                            st.session_state.pop(k, None)

                    st.session_state['df_processed'][new_col_name] = st.session_state['df_processed'][col_to_duplicate].copy()
                    st.session_state["duplicated_col_name"] = new_col_name
                    # Initialize the rename map for the newly duplicated column
                    if f"rename_map_{new_col_name}" not in st.session_state:
                         st.session_state[f"rename_map_{new_col_name}"] = {}
                    st.success(f"Coluna '{col_to_duplicate}' duplicada como '{new_col_name}'.")
                    st.rerun() # Rerun to update the `col_duplicada` logic immediately
            else:
                st.info("Selecione uma coluna para duplicar.")


            # If duplication was made, allow renaming
            col_duplicada = st.session_state.get("duplicated_col_name", None)

            if col_duplicada and col_duplicada in st.session_state['df_processed'].columns:
                st.markdown(f"### Renomear valores da nova coluna '{col_duplicada}' (opcional)")

                # Ensure unique values are pulled from the *current* df_processed for the duplicated column
                # This is important if df_processed changes due to other operations
                unique_vals = st.session_state['df_processed'][col_duplicada].dropna().unique().tolist()
                
                # Initialize rename map if not already present for this specific duplicated column
                if f"rename_map_{col_duplicada}" not in st.session_state:
                    st.session_state[f"rename_map_{col_duplicada}"] = {}

                rename_map = st.session_state[f"rename_map_{col_duplicada}"]

                st.write("Digite o novo valor para cada valor √∫nico existente:")
                for i, val in enumerate(unique_vals):
                    # Ensure keys are unique across reruns and tied to the specific duplicated column and original value
                    default_val = rename_map.get(val, str(val))
                    key_val_input = f"rename_value_{col_duplicada}_{val}_{i}" # Added index for more uniqueness
                    new_val_input = st.text_input(f"Novo valor para '{val}':", value=default_val, key=key_val_input)
                    rename_map[val] = new_val_input

                st.session_state[f"rename_map_{col_duplicada}"] = rename_map

                if st.button("Aplicar Renomea√ß√£o de Valores", key="apply_value_renaming_btn"):
                    if not rename_map:
                        st.warning("Nenhum mapeamento de renomea√ß√£o de valores foi definido.")
                    else:
                        try:
                            st.session_state['df_processed'] = rename_column_values(
                                st.session_state['df_processed'],
                                col_duplicada,
                                st.session_state[f"rename_map_{col_duplicada}"]
                            )
                            st.success(f"Valores da coluna '{col_duplicada}' foram renomeados com sucesso.")
                            st.session_state['last_preprocessing_log'].append(f"Valores na coluna '{col_duplicada}' renomeados.")
                            st.session_state['preprocessing_applied_flag'] = True
                            st.rerun()
                        except Exception as e:
                            st.error(f"Erro ao renomear valores: {e}")
                            st.session_state['last_preprocessing_log'].append(f"Erro ao renomear valores na coluna '{col_duplicada}': {e}")
                            st.session_state['preprocessing_applied_flag'] = False
            else:
                st.info("Nenhuma coluna duplicada ainda. Duplique uma coluna primeiro para renomear seus valores.")
        else:
            st.info("O DataFrame de trabalho est√° vazio. Por favor, selecione e processe colunas antes de usar esta funcionalidade.")


    # --- Exibi√ß√£o dos resultados do pr√©-processamento ---
    st.markdown("---")
    if st.session_state.get('preprocessing_applied_flag', False):
        st.subheader("Pr√©-processamento Conclu√≠do!")
        for log_entry in st.session_state['last_preprocessing_log']:
            st.success(f"- {log_entry}")
    elif st.session_state.get('last_preprocessing_log'):
        st.subheader("Status do Pr√©-processamento:")
        for log_entry in st.session_state['last_preprocessing_log']:
            st.info(f"- {log_entry}")
    else:
        st.info("Nenhuma opera√ß√£o de pr√©-processamento aplicada ainda.")


    st.markdown("---")
    st.subheader("Pr√©via do DataFrame Processado Atualmente")
    if st.session_state.df_processed is not None and not st.session_state.df_processed.empty:
        st.dataframe(st.session_state.df_processed.head())
        st.write(f"Dimens√µes: {st.session_state['df_processed'].shape[0]} linhas, {st.session_state['df_processed'].shape[1]} colunas.")
        st.write("Tipos de Dados Atuais:")
        st.dataframe(st.session_state.df_processed.dtypes.astype(str))
    else:
        st.info("O DataFrame de trabalho est√° vazio ou n√£o foi processado ainda.")