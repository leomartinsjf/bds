#correto
import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from statsmodels.formula.api import ols, glm, mixedlm
import re


# Apenas para fins de demonstra√ß√£o, crie um DataFrame dummy se n√£o existir
if 'df_processed' not in st.session_state:
    np.random.seed(42) 
    data = {
        'Target_Linear': np.random.normal(50, 15, 200),
        'Feature_A': np.random.normal(10, 2, 200),
        'Feature_B': np.random.rand(200) * 5,
        'Category_C': np.random.choice(['X', 'Y', 'Z'], 200),
        'Target_Logistic': np.random.randint(0, 2, 200),
        'Feature_D': np.random.normal(25, 5, 200),
        'Feature_E': np.random.rand(200) * 10,
        'Group_ID': np.random.choice([f'G{i}' for i in range(1, 11)], 200),
        'Random_Slope_Var': np.random.rand(200) * 3,
        'Target_Multilevel': np.random.normal(100, 20, 200),
        'X_Predictor': np.random.normal(10, 2, 200), # Para Path Analysis
        'M_Mediator': np.random.normal(5, 1, 200),   # Para Path Analysis
        'Y_Outcome': np.random.normal(20, 4, 200),    # Para Path Analysis
        'Z_Covariate': np.random.normal(15, 3, 200) # Para Path Analysis
    }
    data['Target_Linear'] += data['Feature_A'] * 2 + data['Feature_B'] * 1.5 + np.random.normal(0, 5, 200)
    data['Target_Logistic'] = (data['Feature_D'] * 0.2 + data['Feature_E'] * 0.1 + np.random.normal(0, 0.5, 200) > 6).astype(int)
    
    group_effects = {f'G{i}': np.random.normal(0, 5) for i in range(1, 11)}
    data['Target_Multilevel'] += [group_effects[g] for g in data['Group_ID']]
    data['Target_Multilevel'] += data['Feature_A'] * 3 + data['Random_Slope_Var'] * 2 + np.random.normal(0, 10, 200)

    # Simular rela√ß√µes para Path Analysis: X -> M -> Y e X -> Y
    data['M_Mediator'] += data['X_Predictor'] * 0.6 + np.random.normal(0, 1, 200)
    data['Y_Outcome'] += data['X_Predictor'] * 0.3 + data['M_Mediator'] * 0.5 + np.random.normal(0, 2, 200)
    data['M_Mediator'] += data['Z_Covariate'] * 0.2 # Z covaria com M
    
    st.session_state['df_processed'] = pd.DataFrame(data)
    st.session_state['df_processed']['Group_ID'] = st.session_state['df_processed']['Group_ID'].astype('category')


# --- Fun√ß√£o para Regress√£o Linear ---
def show_linear_regression_model():
    st.subheader("üìà Regress√£o Linear")
    st.info("Utilize a Regress√£o Linear para prever uma vari√°vel dependente cont√≠nua com base em uma ou mais vari√°veis independentes num√©ricas.")

    if 'df_processed' not in st.session_state or st.session_state.df_processed is None or st.session_state.df_processed.empty:
        st.warning("Nenhum dado processado dispon√≠vel. Por favor, carregue e pr√©-processe os dados primeiro.")
        return

    # Adicionando o expander para toda a se√ß√£o de configura√ß√£o e resultados da regress√£o linear
    with st.expander("Configurar e Executar Regress√£o Linear", expanded=False): # 'expanded=True' para come√ßar aberto
        df = st.session_state.df_processed.copy()
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        
        if not numeric_cols:
            st.warning("N√£o h√° colunas num√©ricas no DataFrame para realizar a Regress√£o Linear.")
            return

        st.markdown("---")
        st.markdown("#### Configura√ß√£o do Modelo de Regress√£o Linear")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 1. Selecione a Vari√°vel Dependente (Y)")
        dependent_var = st.selectbox(
            "Escolha a vari√°vel cont√≠nua a ser prevista:", 
            numeric_cols, 
            key="lr_dependent"
        )
        if dependent_var:
            st.success(f"Vari√°vel Dependente selecionada: **{dependent_var}**")
        else:
            st.warning("Por favor, selecione uma vari√°vel dependente.")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 2. Selecione as Vari√°veis Independentes (X)")
        options_independent_vars = [col for col in numeric_cols if col != dependent_var]
        if not options_independent_vars:
            st.warning("N√£o h√° vari√°veis num√©ricas dispon√≠veis para usar como preditoras, exceto a vari√°vel dependente selecionada.")
        independent_vars = st.multiselect(
            "Escolha uma ou mais vari√°veis num√©ricas para prever a vari√°vel dependente:", 
            options_independent_vars, 
            key="lr_independent"
        )
        if independent_vars:
            st.success(f"Vari√°veis Independentes selecionadas: **{', '.join(independent_vars)}**")
        else:
            st.warning("Por favor, selecione pelo menos uma vari√°vel independente.")

        if dependent_var is None or not independent_vars:
            st.info("Por favor, complete as sele√ß√µes obrigat√≥rias para a Vari√°vel Dependente e Vari√°veis Independentes.")
            return

        if st.button("Executar Regress√£o Linear", key="run_lr_model"):
            with st.spinner("Treinando Modelo de Regress√£o Linear..."):
                try:
                    model_vars = [dependent_var] + independent_vars
                    df_model = df[model_vars].dropna()
                    
                    initial_rows = df.shape[0]
                    if initial_rows > df_model.shape[0]:
                        st.warning(f"Foram removidas {initial_rows - df_model.shape[0]} linhas devido a valores NaN nas vari√°veis selecionadas para o modelo.")

                    if df_model.empty:
                        st.error("N√£o h√° dados suficientes ap√≥s o tratamento de NaN para construir o modelo.")
                        return

                    Y = df_model[dependent_var]
                    X = df_model[independent_vars]
                    X = sm.add_constant(X)

                    model = sm.OLS(Y, X)
                    results = model.fit()

                    st.markdown("---")
                    st.subheader("Resultados da Regress√£o Linear")

                    st.write("#### Sum√°rio do Modelo (Statsmodels OLS)")
                    st.code(results.summary().as_text())

                    st.info("Os coeficientes ('coef') indicam a mudan√ßa m√©dia na vari√°vel dependente para cada aumento de uma unidade na vari√°vel independente correspondente, mantendo as outras constantes.")
                    st.info("O 'P>|t|' (p-valor) indica a signific√¢ncia estat√≠stica do coeficiente. Valores abaixo de 0.05 (geralmente) sugerem um efeito significativo.")
                    st.info("O R-quadrado ajustado ('Adj. R-squared') representa a propor√ß√£o da vari√¢ncia na vari√°vel dependente que √© explicada pelas vari√°veis independentes.")

                    st.write("#### M√©tricas de Avalia√ß√£o")
                    predictions = results.predict(X)
                    r2 = r2_score(Y, predictions)
                    mse = mean_squared_error(Y, predictions)
                    rmse = np.sqrt(mse)

                    st.write(f"**R-quadrado (R¬≤):** `{r2:.4f}`")
                    st.write(f"**Erro Quadr√°tico M√©dio (MSE):** `{mse:.4f}`")
                    st.write(f"**Raiz do Erro Quadr√°tico M√©dio (RMSE):** `{rmse:.4f}`")

                    st.write("#### An√°lise de Res√≠duos")
                    fig_res, ax_res = plt.subplots(figsize=(10, 6))
                    sns.scatterplot(x=predictions, y=results.resid, ax=ax_res)
                    ax_res.axhline(0, color='red', linestyle='--')
                    ax_res.set_xlabel("Valores Preditos")
                    ax_res.set_ylabel("Res√≠duos")
                    ax_res.set_title("Res√≠duos vs. Valores Preditos")
                    st.pyplot(fig_res)
                    plt.close(fig_res)
                    st.info("Este gr√°fico ajuda a verificar a suposi√ß√£o de homocedasticidade (vari√¢ncia constante dos res√≠duos). Os res√≠duos devem estar espalhados aleatoriamente em torno de zero.")
                    
                    fig_hist_res, ax_hist_res = plt.subplots(figsize=(10, 6))
                    sns.histplot(results.resid, kde=True, ax=ax_hist_res)
                    ax_hist_res.set_xlabel("Res√≠duos")
                    ax_hist_res.set_ylabel("Frequ√™ncia")
                    ax_hist_res.set_title("Distribui√ß√£o dos Res√≠duos")
                    st.pyplot(fig_hist_res)
                    plt.close(fig_hist_res)
                    st.info("A distribui√ß√£o dos res√≠duos deve ser aproximadamente normal. Uma distribui√ß√£o em forma de sino sugere que a suposi√ß√£o de normalidade foi atendida.")

                except Exception as e:
                    st.error(f"Erro ao executar a Regress√£o Linear: {e}")
                    st.info("Verifique se as vari√°veis selecionadas s√£o num√©ricas e se h√° dados suficientes. Erros comuns incluem multicolinearidade ou problemas de dados.")


# --- Fun√ß√£o para Regress√£o Log√≠stica ---
def show_logistic_regression_model():
    st.subheader("üìä Regress√£o Log√≠stica")
    st.info("Utilize a Regress√£o Log√≠stica para prever uma vari√°vel dependente categ√≥rica bin√°ria (0 ou 1, sim/n√£o) com base em uma ou mais vari√°veis independentes.")

    if 'df_processed' not in st.session_state or st.session_state.df_processed is None or st.session_state.df_processed.empty:
        st.warning("Nenhum dado processado dispon√≠vel. Por favor, carregue e pr√©-processe os dados primeiro.")
        return

    # Adicionando o expander para toda a se√ß√£o de configura√ß√£o e resultados da regress√£o log√≠stica
    with st.expander("Configurar e Executar Regress√£o Log√≠stica", expanded=False): # 'expanded=True' para come√ßar aberto
        df = st.session_state.df_processed.copy()
        all_cols = df.columns.tolist()
        
        binary_cols = [col for col in all_cols if df[col].nunique() == 2 and df[col].isin([0, 1]).all()]
        
        if not binary_cols:
            st.warning("N√£o h√° colunas bin√°rias (0 ou 1) no DataFrame para a vari√°vel dependente.")
            return

        st.markdown("---")
        st.markdown("#### Configura√ß√£o do Modelo de Regress√£o Log√≠stica")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 1. Selecione a Vari√°vel Dependente (Y - Bin√°ria)")
        dependent_var = st.selectbox(
            "Escolha a vari√°vel bin√°ria (0 ou 1) a ser prevista:", 
            binary_cols, 
            key="logr_dependent"
        )
        if dependent_var:
            st.success(f"Vari√°vel Dependente selecionada: **{dependent_var}**")
            unique_vals = df[dependent_var].unique()
            st.info(f"Valores √∫nicos da vari√°vel dependente: {unique_vals[0]} e {unique_vals[1]}. O modelo prediz a probabilidade do valor `1`.")
        else:
            st.warning("Por favor, selecione uma vari√°vel dependente bin√°ria.")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 2. Selecione as Vari√°veis Independentes (X)")
        options_independent_vars = [col for col in all_cols if col != dependent_var]
        independent_vars = st.multiselect(
            "Escolha uma ou mais vari√°veis para prever a vari√°vel dependente:", 
            options_independent_vars, 
            key="logr_independent"
        )
        if independent_vars:
            st.success(f"Vari√°veis Independentes selecionadas: **{', '.join(independent_vars)}**")
        else:
            st.warning("Por favor, selecione pelo menos uma vari√°vel independente.")

        if dependent_var is None or not independent_vars:
            st.info("Por favor, complete as sele√ß√µes obrigat√≥rias para a Vari√°vel Dependente e Vari√°veis Independentes.")
            return

        if st.button("Executar Regress√£o Log√≠stica", key="run_logr_model"):
            with st.spinner("Treinando Modelo de Regress√£o Log√≠stica..."):
                try:
                    model_vars = [dependent_var] + independent_vars
                    df_model = df[model_vars].dropna()
                    
                    initial_rows = df.shape[0]
                    if initial_rows > df_model.shape[0]:
                        st.warning(f"Foram removidas {initial_rows - df_model.shape[0]} linhas devido a valores NaN nas vari√°veis selecionadas para o modelo.")

                    if df_model.empty:
                        st.error("N√£o h√° dados suficientes ap√≥s o tratamento de NaN para construir o modelo.")
                        return

                    X = df_model[independent_vars]
                    for col in X.columns:
                        if pd.api.types.is_categorical_dtype(X[col]) or pd.api.types.is_object_dtype(X[col]):
                            X = pd.get_dummies(X, columns=[col], drop_first=True, dtype=int)

                    Y = df_model[dependent_var]
                    X = sm.add_constant(X, prepend=False)

                    model = sm.GLM(Y, X, family=sm.families.Binomial())
                    results = model.fit()

                    st.markdown("---")
                    st.subheader("Resultados da Regress√£o Log√≠stica")

                    st.write("#### Sum√°rio do Modelo (Statsmodels GLM - Log√≠stica)")
                    st.code(results.summary().as_text())

                    st.info("Os coeficientes ('coef') indicam a mudan√ßa no log-odds da vari√°vel dependente para cada aumento de uma unidade na vari√°vel independente. Valores positivos aumentam a probabilidade de ocorr√™ncia do evento (valor 1).")
                    st.info("O 'P>|z|' (p-valor) indica a signific√¢ncia estat√≠stica do coeficiente. Valores abaixo de 0.05 (geralmente) sugerem um efeito significativo.")
                    
                    st.write("#### M√©tricas de Avalia√ß√£o")
                    predictions_proba = results.predict(X)
                    
                    threshold = st.slider("Selecione o Ponto de Corte (Threshold) para Classifica√ß√£o:", 0.0, 1.0, 0.5, 0.01, key="logr_threshold")
                    predictions_class = (predictions_proba >= threshold).astype(int)

                    accuracy = accuracy_score(Y, predictions_class)
                    precision = precision_score(Y, predictions_class)
                    recall = recall_score(Y, predictions_class)
                    f1 = f1_score(Y, predictions_class)
                    auc_score = roc_auc_score(Y, predictions_proba)
                    cm = confusion_matrix(Y, predictions_class)

                    st.write(f"**Acur√°cia:** `{accuracy:.4f}`")
                    st.write(f"**Precis√£o:** `{precision:.4f}`")
                    st.write(f"**Recall:** `{recall:.4f}`")
                    st.write(f"**F1-Score:** `{f1:.4f}`")
                    st.write(f"**AUC (Area Under ROC Curve):** `{auc_score:.4f}`")

                    st.write("##### Matriz de Confus√£o:")
                    fig_cm, ax_cm = plt.subplots(figsize=(6, 6))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax_cm,
                                xticklabels=['Predito 0', 'Predito 1'], yticklabels=['Real 0', 'Real 1'])
                    ax_cm.set_xlabel("Predito")
                    ax_cm.set_ylabel("Real")
                    ax_cm.set_title("Matriz de Confus√£o")
                    st.pyplot(fig_cm)
                    plt.close(fig_cm)
                    st.info("A matriz de confus√£o mostra o n√∫mero de verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos.")

                    st.write("##### Curva ROC")
                    fpr, tpr, _ = roc_curve(Y, predictions_proba)
                    fig_roc, ax_roc = plt.subplots(figsize=(8, 6))
                    ax_roc.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')
                    ax_roc.plot([0, 1], [0, 1], 'r--', label='Linha de Refer√™ncia')
                    ax_roc.set_xlabel("Taxa de Falso Positivo (FPR)")
                    ax_roc.set_ylabel("Taxa de Verdadeiro Positivo (TPR)")
                    ax_roc.set_title("Curva Caracter√≠stica de Opera√ß√£o do Receptor (ROC)")
                    ax_roc.legend()
                    st.pyplot(fig_roc)
                    plt.close(fig_roc)
                    st.info("A Curva ROC avalia o desempenho do classificador em v√°rios pontos de corte. Um AUC pr√≥ximo de 1.0 indica um excelente poder de discrimina√ß√£o.")

                except Exception as e:
                    st.error(f"Erro ao executar a Regress√£o Log√≠stica: {e}")
                    st.info("Verifique se a vari√°vel dependente √© bin√°ria (0 ou 1) e se h√° dados suficientes. Erros comuns incluem classes desbalanceadas ou problemas de converg√™ncia.")


# --- Fun√ß√£o para An√°lise Multin√≠vel (Modelos Lineares Mistos) ---
def show_multilevel_model():
    st.subheader("üå≥ An√°lise Multin√≠vel (Modelos Lineares Mistos)")
    st.info("Utilize a An√°lise Multin√≠vel para modelar dados com estrutura hier√°rquica ou aninhada (ex: estudantes em escolas, pacientes em hospitais).")
    st.info("Esta an√°lise permite que os efeitos das vari√°veis variem entre os diferentes grupos.")

    if 'df_processed' not in st.session_state or st.session_state.df_processed is None or st.session_state.df_processed.empty:
        st.warning("Nenhum dado processado dispon√≠vel. Por favor, carregue e pr√©-processe os dados primeiro.")
        return

    # Adicionando o expander para toda a se√ß√£o de configura√ß√£o e resultados da an√°lise multin√≠vel
    with st.expander("Configurar e Executar An√°lise Multin√≠vel", expanded=False): # 'expanded=True' para come√ßar aberto
        df = st.session_state.df_processed.copy()
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
        all_cols = df.columns.tolist()

        if not numeric_cols:
            st.warning("N√£o h√° colunas num√©ricas no DataFrame para a vari√°vel dependente.")
            return
        if not categorical_cols:
            st.warning("N√£o h√° colunas categ√≥ricas no DataFrame para a vari√°vel de agrupamento (n√≠vel superior).")
            return

        st.markdown("---")
        st.markdown("#### Configura√ß√£o do Modelo Multin√≠vel")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 1. Selecione a Vari√°vel Dependente (Y)")
        dependent_var = st.selectbox(
            "Escolha a vari√°vel cont√≠nua a ser prevista:", 
            numeric_cols, 
            key="mlm_dependent"
        )
        if dependent_var:
            st.success(f"Vari√°vel Dependente selecionada: **{dependent_var}**")
        else:
            st.warning("Por favor, selecione uma vari√°vel dependente.")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 2. Selecione a Vari√°vel de Agrupamento")
        group_var = st.selectbox(
            "Escolha a vari√°vel categ√≥rica que define os grupos (n√≠vel superior):", 
            categorical_cols, 
            key="mlm_group"
        )
        if group_var:
            st.success(f"Vari√°vel de Agrupamento selecionada: **{group_var}**")
        else:
            st.warning("Por favor, selecione uma vari√°vel de agrupamento.")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 3. Selecione as Vari√°veis de Efeitos Fixos")
        options_fixed_effects = [col for col in all_cols if col != dependent_var and col != group_var]
        fixed_effects_vars = st.multiselect(
            "Escolha as vari√°veis preditoras que afetam todos os grupos da mesma forma:", 
            options_fixed_effects, 
            key="mlm_fixed_effects"
        )
        if fixed_effects_vars:
            st.success(f"Vari√°veis de Efeitos Fixos selecionadas: **{', '.join(fixed_effects_vars)}**")
        else:
            st.info("Nenhuma vari√°vel de efeito fixo selecionada. O modelo pode incluir apenas um intercepto fixo e efeitos aleat√≥rios.")

        # N√ÉO MAIS EXPANDER ANINHADO AQUI
        st.markdown("##### 4. Selecione os Efeitos Aleat√≥rios")
        selected_random_effects = []
        random_effects_options = ["Intercepto Aleat√≥rio"] + [
            col for col in fixed_effects_vars if col in numeric_cols 
        ]
        
        default_random_effects = []
        if "Intercepto Aleat√≥rio" in random_effects_options:
            default_random_effects.append("Intercepto Aleat√≥rio")

        selected_random_effects = st.multiselect(
            "Escolha quais componentes devem variar aleatoriamente entre os grupos (o intercepto √© comum):",
            random_effects_options,
            default=default_random_effects,
            key="mlm_random_effects"
        )
        if selected_random_effects:
            st.success(f"Efeitos Aleat√≥rios selecionados: **{', '.join(selected_random_effects)}**")
        else:
            st.warning("Por favor, selecione pelo menos um efeito aleat√≥rio (geralmente o Intercepto Aleat√≥rio).")

        if dependent_var is None or group_var is None or not selected_random_effects:
            st.info("Por favor, complete as sele√ß√µes obrigat√≥rias para a Vari√°vel Dependente, Vari√°vel de Agrupamento e Efeitos Aleat√≥rios.")
            return

        if st.button("Executar An√°lise Multin√≠vel", key="run_mlm_model"):
            with st.spinner("Treinando Modelo Multin√≠vel..."):
                try:
                    model_vars = [dependent_var, group_var] + fixed_effects_vars 
                    
                    for re_var in selected_random_effects:
                        if re_var != "Intercepto Aleat√≥rio" and re_var not in model_vars:
                            model_vars.append(re_var)

                    df_model = df[model_vars].dropna()
                    
                    initial_rows = df.shape[0]
                    if initial_rows > df_model.shape[0]:
                        st.warning(f"Foram removidas {initial_rows - df_model.shape[0]} linhas devido a valores NaN nas vari√°veis selecionadas para o modelo multin√≠vel.")

                    if df_model.empty:
                        st.error("N√£o h√° dados suficientes ap√≥s o tratamento de NaN para construir o modelo multin√≠vel.")
                        return

                    if not pd.api.types.is_categorical_dtype(df_model[group_var]):
                        df_model[group_var] = df_model[group_var].astype('category')
                        st.info(f"A vari√°vel de agrupamento '{group_var}' foi convertida para tipo categ√≥rica.")

                    fixed_part = " + ".join(fixed_effects_vars) if fixed_effects_vars else "1" 
                    
                    random_part_for_re_formula = []
                    if "Intercepto Aleat√≥rio" in selected_random_effects:
                        random_part_for_re_formula.append("1") 
                    
                    for re_var in selected_random_effects:
                        if re_var != "Intercepto Aleat√≥rio":
                            if re_var in numeric_cols:
                                random_part_for_re_formula.append(re_var)
                            else:
                                st.warning(f"Vari√°vel '{re_var}' selecionada para efeito aleat√≥rio n√£o √© num√©rica e ser√° ignorada para slopes aleat√≥rios.")
                    
                    re_formula_str = "~ " + " + ".join(random_part_for_re_formula)
                    
                    formula = f"{dependent_var} ~ {fixed_part}"

                    model = mixedlm(
                        formula=formula, 
                        data=df_model, 
                        re_formula=re_formula_str, 
                        groups=df_model[group_var]
                    )
                    
                    results = model.fit()

                    st.markdown("---")
                    st.subheader("Resultados do Modelo Multin√≠vel")

                    st.write("#### Sum√°rio Completo do Modelo (Statsmodels MixedLM)")
                    st.code(results.summary().as_text())

                    st.info("Os coeficientes na se√ß√£o 'Coefs' representam os efeitos fixos. Eles s√£o interpretados como em uma regress√£o linear comum.")
                    st.info("A se√ß√£o **'Random Effects'** no sum√°rio completo do modelo (exibido acima) cont√©m a vari√¢ncia e o desvio padr√£o dos efeitos aleat√≥rios (intercepto e/ou slopes), indicando o quanto esses efeitos variam entre os grupos. **Por favor, consulte essa se√ß√£o para os valores num√©ricos detalhados.**")
                    st.info("Um 'P>|z|' baixo (geralmente < 0.05) para um efeito fixo indica signific√¢ncia estat√≠stica.")
                    
                    st.subheader("Vari√¢ncia e Desvio Padr√£o dos Componentes do Modelo")
                    
                    if hasattr(results, 'vc_params') and results.vc_params is not None and not results.vc_params.empty:
                        st.write("##### Vari√¢ncia e Desvio Padr√£o dos Efeitos Aleat√≥rios por Componente")
                        
                        vc_df = results.vc_params.to_frame(name='Vari√¢ncia Estimada')
                        vc_df['Desvio Padr√£o Estimado'] = np.sqrt(vc_df['Vari√¢ncia Estimada'])
                        st.dataframe(vc_df)
                        st.markdown(f"**Interpreta√ß√£o:** Estas s√£o as vari√¢ncias e desvios padr√£o dos componentes de efeitos aleat√≥rios que variam entre os grupos de `{group_var}`.")
                        
                    else:
                        st.info("N√£o foi poss√≠vel extrair a vari√¢ncia de efeitos aleat√≥rios explicitamente de `vc_params`. Por favor, consulte a se√ß√£o 'Random Effects' no sum√°rio completo do modelo acima.")

                    st.write("##### Vari√¢ncia e Desvio Padr√£o do Termo de Erro (Residual)")
                    st.write(f"Vari√¢ncia Residual (Scale): `{results.scale:.4f}`")
                    st.write(f"Desvio Padr√£o Residual (Scale): `{np.sqrt(results.scale):.4f}`")
                    st.markdown("**Interpreta√ß√£o:** Esta √© a vari√¢ncia do erro n√£o explicada pelo modelo.")


                    st.subheader("Visualiza√ß√£o dos Efeitos Aleat√≥rios Estimados por Grupo")
                    
                    random_effects_df = pd.DataFrame(results.random_effects).T 

                    if not random_effects_df.empty:
                        st.write("Tabela de Efeitos Aleat√≥rios Estimados (Primeiras 5 Linhas):")
                        st.dataframe(random_effects_df.head())

                        for effect_name in random_effects_df.columns:
                            fig, axes = plt.subplots(1, 2, figsize=(12, 5))
                            
                            sns.histplot(random_effects_df[effect_name], kde=True, ax=axes[0])
                            axes[0].set_title(f"Distribui√ß√£o do Efeito Aleat√≥rio: {effect_name}")
                            axes[0].set_xlabel(f"Valor do Efeito Aleat√≥rio ({effect_name})")
                            axes[0].set_ylabel("Frequ√™ncia")

                            sns.boxplot(x=random_effects_df[effect_name], ax=axes[1])
                            axes[1].set_title(f"Box Plot do Efeito Aleat√≥rio: {effect_name}")
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close(fig)

                            st.info(f"O gr√°fico de '{effect_name}' mostra a distribui√ß√£o dos desvios para cada grupo em rela√ß√£o ao valor m√©dio fixo deste efeito. Uma maior dispers√£o indica maior variabilidade entre os grupos.")
                    else:
                        st.info("Nenhum efeito aleat√≥rio estimado para visualizar ou o modelo n√£o convergiu adequadamente.")

                except Exception as e:
                    st.error(f"Erro ao executar a an√°lise multin√≠vel: {e}")
                    st.info("Verifique se as vari√°veis selecionadas s√£o apropriadas para o tipo de modelo (ex: vari√°veis num√©ricas para dependente e slopes aleat√≥rios, categ√≥ricas para agrupamento). Tamb√©m verifique se n√£o h√° valores NaN nas vari√°veis do modelo.")


# --- FUN√á√ÉO PARA AN√ÅLISE DE CAMINHO (PATH ANALYSIS) com Statsmodels e c√°lculo manual ---
def show_path_analysis_model():
    st.subheader("üï∏Ô∏è An√°lise de Caminhos (Path Analysis)")
    st.info("A An√°lise de Caminhos permite testar um modelo te√≥rico de rela√ß√µes causais entre vari√°veis observadas, utilizando uma s√©rie de regress√µes. Ser√£o exibidos os resultados num√©ricos dos efeitos diretos, indiretos e totais.")
    st.info("Para uma interpreta√ß√£o correta dos coeficientes de caminho, as vari√°veis s√£o padronizadas antes da modelagem.")

    if 'df_processed' not in st.session_state or st.session_state.df_processed is None or st.session_state.df_processed.empty:
        st.warning("Nenhum dado processado dispon√≠vel. Por favor, carregue e pr√©-processe os dados primeiro.")
        return

    # Adicionando o expander para toda a se√ß√£o de configura√ß√£o e resultados da an√°lise de caminhos
    with st.expander("Configurar e Executar An√°lise de Caminhos", expanded=False): # 'expanded=True' para come√ßar aberto
        df = st.session_state.df_processed.copy()
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

        if not numeric_cols:
            st.warning("N√£o h√° colunas num√©ricas no DataFrame para realizar a An√°lise de Caminhos.")
            return

        st.markdown("---")
        st.markdown("#### Definir Rela√ß√µes de Caminho")
        st.info("Para cada vari√°vel dependente (end√≥gena) no seu modelo, defina as vari√°veis independentes (ex√≥genas ou outras end√≥genas) que a predizem.")
        st.info("Use o formato SEM: `dependente ~ independente1 + independente2`. Cada linha define uma equa√ß√£o de regress√£o.")

        model_syntax_input = st.text_area(
            "Defina as rela√ß√µes do modelo:",
            value="""# Exemplo de modelo de caminhos:
# M_Mediator ~ X_Predictor
# Y_Outcome ~ X_Predictor + M_Mediator
# Observa√ß√£o: 'M_Mediator' √© uma vari√°vel mediadora aqui.
# A ordem das equa√ß√µes n√£o importa para o c√°lculo, mas sim para a interpreta√ß√£o.
""",
            height=200,
            key="pa_model_syntax_input"
        )

        path_equations = []
        all_involved_vars = set() # Para coletar todas as vari√°veis que ser√£o padronizadas
        pattern = re.compile(r"^\s*#.*$|^\s*(\w+)\s*~\s*(.+)$")
        
        for line in model_syntax_input.split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            match = pattern.match(line)
            if match:
                dependent_var = match.group(1).strip()
                independent_vars_str = match.group(2).strip()
                independent_vars = [var.strip() for var in independent_vars_str.split('+')]
                
                valid_dependent = dependent_var in numeric_cols
                valid_independent = all(var in numeric_cols for var in independent_vars)
                
                if valid_dependent and valid_independent:
                    path_equations.append({'dependent': dependent_var, 'independent': independent_vars, 'syntax': line})
                    all_involved_vars.add(dependent_var)
                    all_involved_vars.update(independent_vars)
                    st.success(f"Rela√ß√£o adicionada: `{line}`")
                else:
                    missing_vars = []
                    if not valid_dependent:
                        missing_vars.append(dependent_var)
                    for var in independent_vars:
                        if var not in numeric_cols:
                            missing_vars.append(var)
                    st.warning(f"Vari√°veis n√£o encontradas no DataFrame para a rela√ß√£o `{line}`: {', '.join(missing_vars)}. Esta rela√ß√£o ser√° ignorada.")
            else:
                st.warning(f"Sintaxe inv√°lida para a linha: `{line}`. Use o formato `dependente ~ independente1 + independente2`.")

        if st.button("Executar An√°lise de Caminhos", key="run_path_analysis_model"):
            if not path_equations:
                st.error("Por favor, defina pelo menos uma rela√ß√£o de caminho v√°lida no formato SEM.")
                return

            
            # Padronizar todas as vari√°veis envolvidas ANTES de qualquer regress√£o
            df_standardized = df.copy() 
            
            # Apenas padroniza as colunas que est√£o na lista all_involved_vars
            if all_involved_vars:
                scaler = StandardScaler()
                cols_to_standardize = [col for col in list(all_involved_vars) if col in numeric_cols]
                
                if cols_to_standardize:
                    # Cria um DataFrame tempor√°rio para escalonamento que cont√©m apenas as colunas relevantes
                    # e as linhas SEM NaNs nessas colunas espec√≠ficas.
                    temp_df_for_scaling = df_standardized[cols_to_standardize].dropna()
                    
                    if not temp_df_for_scaling.empty:
                        # Realiza o escalonamento no DataFrame tempor√°rio
                        scaled_values = scaler.fit_transform(temp_df_for_scaling)
                        
                        # Cria um novo DataFrame a partir dos valores escalonados,
                        # PRESERVANDO O √çNDICE E OS NOMES DAS COLUNAS do temp_df_for_scaling.
                        scaled_df_part = pd.DataFrame(scaled_values, columns=cols_to_standardize, index=temp_df_for_scaling.index)
                        
                        # Atualiza o DataFrame ORIGINAL df_standardized com os valores escalonados,
                        # APENAS PARA AS LINHAS QUE FORAM ESCALONADAS (usando .loc para alinhamento de √≠ndice).
                        df_standardized.loc[scaled_df_part.index, cols_to_standardize] = scaled_df_part
                        
                        st.info(f"Vari√°veis padronizadas (Z-score) para a an√°lise de caminhos: {', '.join(cols_to_standardize)}")
                    else:
                        st.warning("N√£o h√° dados completos (sem NaNs) para padronizar as vari√°veis envolvidas. A an√°lise de caminhos pode n√£o ter coeficientes padronizados confi√°veis.")
                else:
                    st.warning("Nenhuma vari√°vel num√©rica v√°lida para padroniza√ß√£o. A an√°lise de caminhos pode n√£o ter coeficientes padronizados confi√°veis.")
            else:
                st.warning("Nenhuma vari√°vel foi definida nas rela√ß√µes de caminho para padroniza√ß√£o.")


            st.markdown("---")
            st.subheader("Resultados Detalhados das Regress√µes (com Coeficientes Padronizados)")

            # Dicion√°rio para armazenar os coeficientes de caminho (betas) para o c√°lculo dos efeitos
            # Formato: {dependente: {independente: coeficiente_beta}}
            path_coefficients = {} 

            for j, equation in enumerate(path_equations):
                dependent = equation['dependent']
                independent = equation['independent']

                if not independent:
                    st.warning(f"A Rela√ß√£o {j+1} ('{dependent}' predita por nada) n√£o ser√° processada. Selecione vari√°veis independentes.")
                    continue

                st.markdown(f"#### Modelo para: **{dependent}**")
                
                # Usar o DataFrame PADRONIZADO
                X = df_standardized[independent].copy()
                y = df_standardized[dependent].copy()

                # Tratamento de valores NaN (removendo linhas). Importante que X e y correspondam.
                initial_rows = X.shape[0]
                data = pd.concat([X, y], axis=1).dropna()
                X = data[independent]
                y = data[dependent]

                
                if initial_rows > X.shape[0]:
                    st.warning(f"Foram removidas {initial_rows - X.shape[0]} linhas na rela√ß√£o de '{dependent}' devido a valores NaN.")

                if X.empty or y.empty:
                    st.error(f"N√£o h√° dados suficientes ap√≥s o tratamento de NaN para construir o modelo para '{dependent}'. Por favor, verifique se h√° dados completos para as vari√°veis selecionadas.") # Mensagem mais informativa
                    continue

                # Adicionar uma constante ao X para o Statsmodels
                X = sm.add_constant(X)

                try:
                    model = sm.OLS(y, X) # Usar y e X completos para ajuste, ou treinar/testar se quiser m√©tricas de previs√£o
                    results = model.fit()

                    st.write("##### Sum√°rio da Regress√£o (Statsmodels):")
                    st.code(results.summary().as_text())

                    st.write("##### Coeficientes de Caminho Padronizados (Betas) e P-valores:")
                    
                    # Os coeficientes do statsmodels com dados padronizados J√Å S√ÉO os betas
                    coefs_df = results.summary2().tables[1][['Coef.', 'P>|t|']]
                    coefs_df.rename(columns={'Coef.': 'Beta (Coef. Padronizado)', 'P>|t|': 'P-valor'}, inplace=True)
                    coefs_df.index.name = 'Vari√°vel Preditiva'
                    
                    # Armazenar betas para c√°lculo de efeitos indiretos/totais
                    path_coefficients[dependent] = {
                        idx: row['Beta (Coef. Padronizado)'] 
                        for idx, row in coefs_df.iterrows() if idx != 'const'
                    }
                    
                    st.dataframe(coefs_df)

                    r2_eq = r2_score(y, results.predict(X))
                    st.metric(label=f"R-squared para '{dependent}'", value=f"{r2_eq:.4f}")

                except Exception as e:
                    st.error(f"Ocorreu um erro ao treinar o modelo de regress√£o para '{dependent}': {e}")
                    st.warning("Verifique se as colunas selecionadas n√£o cont√™m valores infinitos ou colunas com vari√¢ncia zero.")
                st.markdown("---") # Separador para cada modelo
            
            
            
            st.subheader("Resultados da An√°lise de Caminhos: Efeitos Diretos, Indiretos e Totais")
            st.info("Nesta se√ß√£o, calculamos os efeitos baseados nos coeficientes padronizados (Betas) obtidos nas regress√µes acima.")

            # Calculando efeitos diretos, indiretos e totais
            effects = {}

            # Identificar vari√°veis end√≥genas (dependentes em alguma equa√ß√£o)
            endogenous_vars = set(eq['dependent'] for eq in path_equations)
            # Identificar vari√°veis ex√≥genas (nunca dependentes)
            # Devemos considerar as vari√°veis que est√£o em all_involved_vars mas NUNCA s√£o dependentes
            # em nenhuma das equa√ß√µes definidas.
            defined_dependent_vars = set(eq['dependent'] for eq in path_equations)
            exogenous_vars = all_involved_vars - defined_dependent_vars

            st.write("#### Efeitos Diretos (Betas)")
            direct_effects_df = []
            for dependent, coefs in path_coefficients.items():
                for predictor, beta in coefs.items():
                    direct_effects_df.append({
                        'Origem': predictor,
                        'Destino': dependent,
                        'Efeito Direto (Beta)': f"{beta:.4f}"
                    })
            if direct_effects_df:
                st.dataframe(pd.DataFrame(direct_effects_df))
            else:
                st.info("Nenhum efeito direto calculado.")


            st.write("#### Efeitos Indiretos e Totais (Caminhos de Media√ß√£o Simples)")
            st.warning("Esta se√ß√£o calcula efeitos indiretos e totais para cen√°rios de media√ß√£o simples (X -> M -> Y). Para modelos de caminhos mais complexos, uma interpreta√ß√£o manual ou ferramentas mais avan√ßadas seriam necess√°rias.")

            indirect_effects_list = []

            # Itere sobre as vari√°veis ex√≥genas (potenciais X)
            for exog_var in exogenous_vars:
                # Encontre vari√°veis que s√£o preditas por exog_var (potenciais mediadoras M)
                for mediator_var in endogenous_vars:
                    # Condi√ß√£o 1: Existe um caminho direto de X para M? (exog_var prediz mediator_var)
                    if exog_var in path_coefficients.get(mediator_var, {}): 
                        beta_xm = path_coefficients[mediator_var][exog_var] # Coeficiente X -> M
                        
                        # Encontre vari√°veis que s√£o preditas por mediator_var (potenciais Y)
                        for final_dep_var in endogenous_vars:
                            # Condi√ß√£o 2: Existe um caminho direto de M para Y? (mediator_var prediz final_dep_var)
                            if mediator_var in path_coefficients.get(final_dep_var, {}): 
                                # Condi√ß√£o 3: Y n√£o √© o pr√≥prio X (evita ciclos ou redund√¢ncias)
                                if final_dep_var != exog_var:
                                    beta_my = path_coefficients[final_dep_var][mediator_var] # Coeficiente M -> Y
                                    
                                    indirect_effect = beta_xm * beta_my
                                    
                                    # Coletar o efeito direto de X para Y, se existir na equa√ß√£o de Y
                                    # Se X prediz Y diretamente, ele estar√° em path_coefficients[final_dep_var][exog_var]
                                    direct_effect_xy = path_coefficients.get(final_dep_var, {}).get(exog_var, 0)
                                    total_effect = direct_effect_xy + indirect_effect

                                    indirect_effects_list.append({
                                        'Origem': exog_var,
                                        'Mediador': mediator_var,
                                        'Destino': final_dep_var,
                                        'Efeito Indireto (Beta)': f"{indirect_effect:.4f}",
                                        'Efeito Direto (Beta)': f"{direct_effect_xy:.4f}", # Re-exibe para contexto
                                        'Efeito Total (Beta)': f"{total_effect:.4f}"
                                    })
            
            if indirect_effects_list:
                st.dataframe(pd.DataFrame(indirect_effects_list))
            else:
                st.info("Nenhum efeito indireto de media√ß√£o simples encontrado com as rela√ß√µes definidas.")
                st.info("Verifique se h√° cadeias X -> M e M -> Y onde X √© ex√≥gena (n√£o √© predita por nada no modelo), M √© end√≥gena (√© predita por X e preditora de Y), e X √© preditora de M.")

                
            st.markdown("---")
            st.info("O diagrama de caminhos visual n√£o pode ser gerado no momento. Voc√™ pode usar os resultados dos coeficientes para desenhar o diagrama manualmente ou tentar instalar o Graphviz mais tarde.")